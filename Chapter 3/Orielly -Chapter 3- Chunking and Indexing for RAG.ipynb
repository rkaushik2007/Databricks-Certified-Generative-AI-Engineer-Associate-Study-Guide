{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9229260-c102-4912-b49b-7947163bf589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83E\uDDEA Hands-On Lab: Chunking and Indexing for Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "## \uD83D\uDD0D Scenario\n",
    "\n",
    "You are a data engineer working for a health research organization that maintains a large collection of medical guidelines, research papers, and public health protocols published by organizations such as the CDC and WHO. Researchers, clinicians, and analysts frequently need to query this information using natural language questions, but the source documents are lengthy, inconsistently formatted, and often stored as PDFs or scanned files.\n",
    "\n",
    "To support this use case, your team is building a Retrieval-Augmented Generation (RAG) system on Databricks. The system must ingest medical documents, clean and extract usable text, divide that text into meaningful chunks, and store the results in a form that supports efficient semantic retrieval. The quality of the answers generated by the language model will depend directly on how well the data is prepared, chunked, and indexed.\n",
    "\n",
    "In this lab, you will simulate a realistic end-to-end data preparation workflow for RAG. You will observe how design choices—such as chunk size, overlap, and noise removal—affect retrieval relevance and completeness. By working through this scenario, you will see how data preparation decisions influence downstream retrieval quality and model behavior.\n",
    "\n",
    "---\n",
    "\n",
    "## \uD83C\uDFAF Objective\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. **Extract and clean text** from public medical PDF documents using appropriate parsing or OCR techniques.\n",
    "2. **Apply sentence-based chunking with overlap** to preserve semantic context.\n",
    "3. **Convert chunked text into Delta Lake format** with meaningful metadata.\n",
    "4. **Generate vector embeddings** for document chunks using a hosted embedding endpoint.\n",
    "5. **Index embedded chunks** using Databricks Vector Search for semantic retrieval.\n",
    "6. **Execute similarity-based queries** using natural language prompts.\n",
    "7. **Evaluate how chunk size and granularity influence retrieval precision and relevance** through post-query analysis.\n",
    "8. **Compare retrieval results before and after introducing chunk overlap** and document how precision and relevance change.\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83D\uDCDA Learning Alignment\n",
    "\n",
    "This lab aligns with the learning objective of Chapter 3:\n",
    "\n",
    "> **\"Implement effective data chunking, filtering, and structuring strategies that enhance retrieval quality in RAG pipelines.\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d133ac25-9792-4deb-a8bf-6eee86a7d379",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ⚙️ Step 1: Install Required Libraries\n",
    "\n",
    "Before we begin building our RAG pipeline, we need to install several Python libraries that will enable us to work with PDFs, interact with Databricks services, and build vector search capabilities.\n",
    "\n",
    "### \uD83D\uDCE6 Libraries We're Installing:\n",
    "\n",
    "- **`pymupdf`**: A powerful PDF parsing library that can extract text from both digital and scanned PDFs. It provides robust text extraction capabilities and can handle complex PDF structures.\n",
    "- **`databricks-sdk`**: The official Databricks SDK for Python, which provides programmatic access to Databricks REST APIs, including authentication and workspace management.\n",
    "- **`databricks-vectorsearch`**: The specialized SDK for Databricks Vector Search, enabling us to create, manage, and query vector search indexes for semantic retrieval.\n",
    "\n",
    "### \uD83D\uDD27 Why These Libraries Matter:\n",
    "\n",
    "In a production RAG system, you need reliable tools to:\n",
    "1. **Extract clean text** from various document formats (PDFs, scanned images, etc.)\n",
    "2. **Authenticate and interact** with cloud services securely\n",
    "3. **Build and query vector indexes** efficiently for semantic search\n",
    "\n",
    "### \uD83D\uDCDD Installation Notes:\n",
    "\n",
    "- The `--quiet` flag suppresses verbose installation output\n",
    "- The `--upgrade` flag ensures you get the latest compatible versions\n",
    "- You only need to run this once per cluster session\n",
    "- After installation, we'll restart the Python environment to ensure all packages are properly loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "185fd9f4-33e7-4eda-b94e-b1f83d7d5d8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install required libraries for PDF processing, Databricks SDK, and Vector Search\n",
    "%pip install --quiet pymupdf databricks-sdk --upgrade databricks-vectorsearch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f115b20f-875c-4a8d-b73b-be31541b0875",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Restart Python to load newly installed packages\n",
    "dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a42e83a-2ab0-4c85-b9e8-27405ab0fc57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDCC4 Step 2: Download Sample Documents to DBFS\n",
    "\n",
    "Now that we have our libraries installed, we'll download real-world medical documents to work with. These documents represent the type of content that researchers and clinicians need to query in a production RAG system.\n",
    "\n",
    "### \uD83D\uDCDA Documents We're Using:\n",
    "\n",
    "- **CDC COVID-19 FAQ**: A factsheet from the Centers for Disease Control and Prevention containing frequently asked questions about COVID-19\n",
    "- **WHO Clinical Guidelines**: Clinical management guidelines from the World Health Organization for COVID-19 treatment\n",
    "\n",
    "### \uD83C\uDFAF Why These Documents?\n",
    "\n",
    "These documents are ideal for demonstrating RAG capabilities because they:\n",
    "1. **Contain dense medical information** that requires precise retrieval\n",
    "2. **Use domain-specific terminology** that benefits from semantic search\n",
    "3. **Are publicly available** and represent real-world use cases\n",
    "4. **Vary in structure and length**, demonstrating the need for robust chunking strategies\n",
    "\n",
    "### \uD83D\uDCBE Storage Location:\n",
    "\n",
    "We'll save these files to DBFS (Databricks File System) at `/dbfs/FileStore/rag_docs`. DBFS provides:\n",
    "- **Persistent storage** across cluster restarts\n",
    "- **Easy access** from both Python and Spark\n",
    "- **Integration** with Delta Lake and other Databricks services\n",
    "\n",
    "### \uD83D\uDD0D What to Observe:\n",
    "\n",
    "Pay attention to how we handle potential download failures and verify successful storage. In production systems, robust error handling is critical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c87246d6-2207-4bb3-a358-0ecfae545c5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Define DBFS directory for storing downloaded documents\n",
    "dbfs_path = \"/dbfs/FileStore/rag_docs\"\n",
    "os.makedirs(dbfs_path, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "# List of medical documents to download\n",
    "documents = {\n",
    "    \"cdc_faq.pdf\": \"https://www.cdc.gov/coronavirus/2019-ncov/downloads/2019-ncov-factsheet.pdf\",\n",
    "    \"who_guidelines.pdf\": \"https://apps.who.int/iris/bitstream/handle/10665/338882/WHO-2019-nCoV-clinical-2021.1-eng.pdf\"\n",
    "}\n",
    "\n",
    "# Download and save each document to DBFS\n",
    "for filename, url in documents.items():\n",
    "    print(f\"\uD83D\uDCE5 Downloading {filename}...\")\n",
    "    response = requests.get(url)\n",
    "    full_path = os.path.join(dbfs_path, filename)\n",
    "    with open(full_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"✅ File saved to {full_path}\")\n",
    "\n",
    "# Verify files are accessible via DBFS\n",
    "dbutils.fs.ls(\"dbfs:/FileStore/rag_docs/\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8573c14e-f480-4d90-b8a5-d738caac9d02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83E\uDDF9 Step 3: Extract and Clean PDF Text\n",
    "\n",
    "With our documents downloaded, we now need to extract the text content from the PDFs. This is a critical step in the RAG pipeline because the quality of text extraction directly impacts downstream retrieval quality.\n",
    "\n",
    "### \uD83D\uDD27 Text Extraction Approach:\n",
    "\n",
    "We're using **PyMuPDF (fitz)** for text extraction because it:\n",
    "1. **Handles both digital and scanned PDFs** - Can extract text from PDFs created digitally or from scanned images\n",
    "2. **Preserves text structure** - Maintains paragraph breaks and formatting where possible\n",
    "3. **Performs efficiently** - Fast processing even for large documents\n",
    "4. **Supports OCR integration** - Can be extended with OCR libraries like Tesseract for scanned documents\n",
    "\n",
    "### \uD83E\uDDFC Text Cleaning Strategy:\n",
    "\n",
    "Raw PDF text often contains noise that can degrade retrieval quality. Our cleaning function:\n",
    "- **Removes excessive whitespace** - Consolidates multiple spaces and line breaks\n",
    "- **Strips page headers** - Removes \"Page 1\", \"Page 2\" artifacts\n",
    "- **Normalizes formatting** - Ensures consistent text structure\n",
    "\n",
    "### \uD83C\uDFAF Why Cleaning Matters:\n",
    "\n",
    "In RAG systems, noise in the text can:\n",
    "- **Reduce embedding quality** - Irrelevant tokens dilute semantic meaning\n",
    "- **Decrease retrieval precision** - Noise can cause false matches\n",
    "- **Increase storage costs** - Unnecessary tokens consume vector space\n",
    "\n",
    "### \uD83D\uDCA1 Production Considerations:\n",
    "\n",
    "For scanned documents or images, you would extend this with:\n",
    "- **OCR (Optical Character Recognition)** using libraries like Tesseract or cloud services\n",
    "- **Image preprocessing** to improve OCR accuracy (deskewing, denoising)\n",
    "- **Confidence scoring** to filter low-quality OCR results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5521591d-988c-4450-b2a3-9b3c7f4c74de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # This is PyMuPDF\n",
    "import re\n",
    "\n",
    "# Ensure target directory exists\n",
    "dbfs_dir = \"/dbfs/FileStore/rag_docs\"\n",
    "os.makedirs(dbfs_dir, exist_ok=True)\n",
    "\n",
    "# Utility: Clean extracted text\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean extracted PDF text by removing noise and normalizing formatting.\n",
    "\n",
    "    Args:\n",
    "        text (str): Raw text extracted from PDF\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned text ready for chunking\n",
    "    \"\"\"\n",
    "    # Remove excessive line breaks\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    # Remove page number artifacts\n",
    "    text = re.sub(r\"Page \\d+\", \"\", text, flags=re.IGNORECASE)\n",
    "    return text.strip()\n",
    "\n",
    "# Utility: Extract text from PDF using PyMuPDF\n",
    "def extract_pdf_text(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract all text from a PDF file.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned text from all pages\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "    return clean_text(full_text)\n",
    "\n",
    "# Extract and clean both documents\n",
    "cdc_pdf_path = \"/dbfs/FileStore/rag_docs/cdc_faq.pdf\"\n",
    "who_pdf_path = \"/dbfs/FileStore/rag_docs/who_guidelines.pdf\"\n",
    "\n",
    "print(\"\uD83D\uDCC4 Extracting text from CDC FAQ...\")\n",
    "cdc_text = extract_pdf_text(cdc_pdf_path)\n",
    "print(f\"   Extracted {len(cdc_text)} characters\")\n",
    "\n",
    "print(\"\uD83D\uDCC4 Extracting text from WHO Guidelines...\")\n",
    "who_text = extract_pdf_text(who_pdf_path)\n",
    "print(f\"   Extracted {len(who_text)} characters\")\n",
    "\n",
    "# Save cleaned text files to DBFS for inspection and reuse\n",
    "cdc_txt_path = \"/dbfs/FileStore/rag_docs/cdc_faq_clean.txt\"\n",
    "who_txt_path = \"/dbfs/FileStore/rag_docs/who_guidelines_clean.txt\"\n",
    "\n",
    "with open(cdc_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cdc_text)\n",
    "\n",
    "with open(who_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(who_text)\n",
    "\n",
    "print(\"\\n✅ Text extracted and saved as:\")\n",
    "print(f\"   - {cdc_txt_path}\")\n",
    "print(f\"   - {who_txt_path}\")\n",
    "print(f\"\\n\uD83D\uDCA1 Tip: You can inspect these files to verify text quality before chunking\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd508a3b-78d5-4f18-abd4-030f0d1e04d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ✂️ Step 4: Apply Sentence-Level Chunking with Overlap\n",
    "\n",
    "Now we arrive at one of the most critical steps in RAG: **chunking**. How we divide our documents into chunks directly impacts retrieval quality and the relevance of answers generated by the LLM.\n",
    "\n",
    "### \uD83C\uDFAF Chunking Strategy:\n",
    "\n",
    "We're using **sentence-based chunking with overlap** because:\n",
    "\n",
    "1. **Preserves semantic coherence** - Sentences are natural semantic units\n",
    "2. **Maintains context** - Overlap ensures important information isn't lost at chunk boundaries\n",
    "3. **Optimizes for retrieval** - Chunks are sized to match typical query scope\n",
    "4. **Balances precision and recall** - Not too small (fragmented) or too large (diluted)\n",
    "\n",
    "### \uD83D\uDCCF Chunk Parameters:\n",
    "\n",
    "- **Chunk size: 200 words** - Large enough to contain complete thoughts, small enough for focused retrieval\n",
    "- **Overlap: 50 words** - Ensures context continuity across chunk boundaries\n",
    "\n",
    "### \uD83D\uDD0D Why Overlap Matters:\n",
    "\n",
    "Consider this example:\n",
    "```\n",
    "Chunk 1 (no overlap): \"...patients should isolate for 5 days.\"\n",
    "Chunk 2 (no overlap): \"After isolation, wear a mask for 5 additional days.\"\n",
    "```\n",
    "\n",
    "Without overlap, a query about \"total isolation period\" might miss the complete answer. With overlap:\n",
    "```\n",
    "Chunk 1: \"...patients should isolate for 5 days. After isolation, wear...\"\n",
    "Chunk 2: \"...isolate for 5 days. After isolation, wear a mask for 5 additional days.\"\n",
    "```\n",
    "\n",
    "Both chunks now contain the complete context!\n",
    "\n",
    "### \uD83D\uDCCA Metadata We're Capturing:\n",
    "\n",
    "For each chunk, we store:\n",
    "- **source**: Which document it came from (traceability)\n",
    "- **chunk_id**: Sequential identifier (ordering)\n",
    "- **text**: The actual chunk content (for retrieval)\n",
    "\n",
    "This metadata enables:\n",
    "- **Source attribution** in answers\n",
    "- **Chunk reconstruction** if needed\n",
    "- **Quality analysis** and debugging\n",
    "\n",
    "### \uD83D\uDCBE Storage Format:\n",
    "\n",
    "We're saving to **Delta Lake** because it provides:\n",
    "- **ACID transactions** - Reliable writes\n",
    "- **Time travel** - Version history\n",
    "- **Schema enforcement** - Data quality\n",
    "- **Efficient updates** - For incremental processing\n",
    "\n",
    "### \uD83D\uDCDD Technical Note:\n",
    "\n",
    "We use **NLTK's sentence tokenizer** for intelligent sentence boundary detection. The code downloads both `punkt_tab` (for newer NLTK versions 3.9+) and `punkt` (for older versions) to ensure compatibility across different environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0635bf72-a51a-4f94-bc02-08e06b3d078f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# Download NLTK tokenizer data (punkt_tab for newer NLTK versions, punkt for older)\n",
    "try:\n",
    "    nltk.download(\"punkt_tab\", quiet=True)\n",
    "except:\n",
    "    pass\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Define file paths\n",
    "dbfs_dir = \"/dbfs/FileStore/rag_docs\"\n",
    "cdc_txt_path = os.path.join(dbfs_dir, \"cdc_faq_clean.txt\")\n",
    "who_txt_path = os.path.join(dbfs_dir, \"who_guidelines_clean.txt\")\n",
    "delta_output_path = \"/tmp/rag_chunks\"  # Spark will write Delta here\n",
    "\n",
    "# Load cleaned text\n",
    "with open(cdc_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    cdc_text = f.read()\n",
    "\n",
    "with open(who_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    who_text = f.read()\n",
    "\n",
    "# Document metadata structure\n",
    "documents = [\n",
    "    {\"source\": \"cdc_faq\", \"text\": cdc_text},\n",
    "    {\"source\": \"who_guidelines\", \"text\": who_text}\n",
    "]\n",
    "\n",
    "# Define chunking logic with overlap\n",
    "def chunk_text(text, chunk_size=200, overlap=50):\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks based on sentence boundaries.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text to chunk\n",
    "        chunk_size (int): Target chunk size in words\n",
    "        overlap (int): Number of words to overlap between chunks\n",
    "\n",
    "    Returns:\n",
    "        list: List of text chunks\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        sentence_len = len(words)\n",
    "\n",
    "        # If adding this sentence exceeds chunk size, save current chunk\n",
    "        if current_length + sentence_len > chunk_size:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            # Keep last 'overlap' words for context continuity\n",
    "            current_chunk = current_chunk[-overlap:] if overlap else []\n",
    "            current_length = sum(len(s.split()) for s in current_chunk)\n",
    "\n",
    "        current_chunk.extend(words)\n",
    "        current_length += sentence_len\n",
    "\n",
    "    # Add the final chunk if it exists\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Apply chunking to all documents\n",
    "all_chunks = []\n",
    "for doc in documents:\n",
    "    chunks = chunk_text(doc[\"text\"], chunk_size=200, overlap=50)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        all_chunks.append({\n",
    "            \"source\": doc[\"source\"],\n",
    "            \"chunk_id\": i,\n",
    "            \"text\": chunk\n",
    "        })\n",
    "\n",
    "print(f\"\uD83D\uDCCA Chunking Statistics:\")\n",
    "print(f\"   Total chunks created: {len(all_chunks)}\")\n",
    "print(f\"   CDC chunks: {sum(1 for c in all_chunks if c['source'] == 'cdc_faq')}\")\n",
    "print(f\"   WHO chunks: {sum(1 for c in all_chunks if c['source'] == 'who_guidelines')}\")\n",
    "\n",
    "# Convert to Spark DataFrame and write to Delta\n",
    "chunk_df = pd.DataFrame(all_chunks)\n",
    "spark_df = spark.createDataFrame(chunk_df)\n",
    "\n",
    "spark_df.write.mode(\"overwrite\").format(\"delta\").save(delta_output_path)\n",
    "\n",
    "print(f\"\\n✅ Chunking complete and Delta table saved at: {delta_output_path}\")\n",
    "print(f\"\uD83D\uDCA1 Tip: You can query this Delta table to inspect chunk quality\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab8e2009-8054-48fa-a127-f50707102fc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83E\uDDE0 Step 5: Create an Embedding Endpoint in Databricks\n",
    "\n",
    "To convert our text chunks into vector embeddings, we need a **pretrained embedding model** hosted as a **Databricks Model Serving endpoint**. Embeddings are dense vector representations that capture the semantic meaning of text, enabling similarity-based retrieval.\n",
    "\n",
    "### \uD83C\uDFAF Why Embeddings Matter:\n",
    "\n",
    "Traditional keyword search matches exact words, but embeddings enable **semantic search**:\n",
    "- Query: \"How to prevent COVID transmission?\"\n",
    "- Keyword match: Might miss \"infection control measures\"\n",
    "- Semantic match: Finds related concepts even with different wording\n",
    "\n",
    "### \uD83D\uDD27 Embedding Model Selection:\n",
    "\n",
    "We're using **databricks-bge-large-en** because it:\n",
    "1. **Optimized for retrieval** - Specifically trained for semantic search tasks\n",
    "2. **High-quality embeddings** - 1024-dimensional vectors capture nuanced meaning\n",
    "3. **Production-ready** - Hosted and managed by Databricks\n",
    "4. **Cost-effective** - Pay-per-token pricing with auto-scaling\n",
    "\n",
    "### \uD83D\uDCCB Steps to Create the Embedding Endpoint:\n",
    "\n",
    "1. **Navigate to Serving** in your Databricks workspace:\n",
    "   - Go to: `Workspace → Machine Learning → Serving Endpoints`\n",
    "\n",
    "2. **Click \"Create Endpoint\"**\n",
    "\n",
    "3. **Configure the endpoint**:\n",
    "   - **Name**: `databricks-bge-large-en`\n",
    "   - **Served Model**: Select `databricks-bge-large-en`\n",
    "   - **Task**: `embedding`\n",
    "   - **Model Version**: Use the latest available\n",
    "\n",
    "4. **Important Configuration**:\n",
    "   - **Disable \"Scale to zero\"** - Prevents timeout on first query\n",
    "   - Endpoints can take 2-3 minutes to warm up from cold start\n",
    "   - For production, keep endpoint warm for consistent latency\n",
    "\n",
    "5. **Wait for status**: Endpoint must show **ONLINE** before proceeding\n",
    "\n",
    "### \uD83D\uDCA1 Production Considerations:\n",
    "\n",
    "- **GPU vs CPU**: Use GPU endpoints for large-scale embedding generation\n",
    "- **Batch size**: Larger batches improve throughput but increase latency\n",
    "- **Monitoring**: Track endpoint metrics (latency, throughput, errors)\n",
    "- **Cost optimization**: Balance between performance and cost based on query volume\n",
    "\n",
    "### \uD83D\uDD0D Alternative Models:\n",
    "\n",
    "Depending on your use case, you might consider:\n",
    "- **Multilingual models**: For non-English content\n",
    "- **Domain-specific models**: Fine-tuned for medical, legal, or technical domains\n",
    "- **Smaller models**: For cost optimization with acceptable quality trade-offs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bdceb78-d53d-4204-82b8-bb8348abd2e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDD22 Step 6: Generate Embeddings for Chunked Text\n",
    "\n",
    "Now that we have a running embedding endpoint, we'll convert each chunk of text into a high-dimensional vector representation. This is the step that enables semantic search in our RAG system.\n",
    "\n",
    "### \uD83C\uDFAF What We're Doing:\n",
    "\n",
    "We're creating a **Pandas UDF** (User-Defined Function) that:\n",
    "1. **Processes chunks in batches** - More efficient than one-at-a-time\n",
    "2. **Calls the embedding endpoint** - Uses Databricks REST API\n",
    "3. **Handles errors gracefully** - Ensures robustness in production\n",
    "4. **Returns vector arrays** - Compatible with Vector Search\n",
    "\n",
    "### \uD83D\uDD27 Technical Implementation:\n",
    "\n",
    "The UDF uses an **Iterator pattern** for memory efficiency:\n",
    "- Processes data in batches to avoid loading everything into memory\n",
    "- Sends batches of 10 texts at a time to the endpoint\n",
    "- Validates and converts embeddings to float32 format\n",
    "\n",
    "### \uD83D\uDD10 Authentication:\n",
    "\n",
    "We use the **notebook context API token** for secure authentication:\n",
    "- Token is automatically available in Databricks notebooks\n",
    "- No need to hardcode credentials\n",
    "- Follows security best practices\n",
    "\n",
    "### ⚡ Performance Optimization:\n",
    "\n",
    "- **Batch processing**: Reduces API call overhead\n",
    "- **Text filtering**: Skips empty or very short texts\n",
    "- **Error handling**: Provides clear error messages for debugging\n",
    "\n",
    "### \uD83D\uDCA1 Important Notes:\n",
    "\n",
    "- The endpoint URL will be specific to your workspace\n",
    "- Update the `endpoint_url` variable with your workspace URL\n",
    "- The embedding dimension for BGE-large-en is 1024\n",
    "- Processing time depends on the number of chunks and endpoint capacity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb9f5323-9fc8-46e9-aa5b-7fdbbbba5b35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "import pandas as pd\n",
    "from typing import Iterator\n",
    "\n",
    "# Databricks REST endpoint and token\n",
    "# IMPORTANT: Update this URL with your workspace URL\n",
    "endpoint_url = \"https://adb-YOUR-WORKSPACE-ID.azuredatabricks.net/serving-endpoints/databricks-bge-large-en/invocations\"\n",
    "token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "@pandas_udf(ArrayType(FloatType()))\n",
    "def get_embeddings_udf(texts: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    \"\"\"\n",
    "    Generate embeddings for text chunks using Databricks embedding endpoint.\n",
    "\n",
    "    This UDF processes text in batches for efficiency and handles errors gracefully.\n",
    "\n",
    "    Args:\n",
    "        texts: Iterator of pandas Series containing text chunks\n",
    "\n",
    "    Yields:\n",
    "        pandas Series containing embedding vectors (arrays of floats)\n",
    "    \"\"\"\n",
    "    for batch in texts:\n",
    "        try:\n",
    "            # Clean and filter the batch\n",
    "            clean_batch = batch.dropna().astype(str)\n",
    "            clean_batch = clean_batch[clean_batch.str.len() > 10]  # Skip very short texts\n",
    "\n",
    "            # Process in smaller sub-batches to avoid API limits\n",
    "            max_batch_size = 10\n",
    "            chunks = [clean_batch[i:i+max_batch_size] for i in range(0, len(clean_batch), max_batch_size)]\n",
    "            all_embeddings = []\n",
    "\n",
    "            for chunk in chunks:\n",
    "                # Prepare API request payload\n",
    "                payload = {\"input\": chunk.tolist()}\n",
    "                response = requests.post(endpoint_url, headers=headers, json=payload)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                # Extract embeddings from response\n",
    "                # The response format is: {\"data\": [{\"embedding\": [...]}, ...]}\n",
    "                vectors = [item[\"embedding\"] for item in response.json().get(\"data\", [])]\n",
    "                all_embeddings.extend(vectors)\n",
    "\n",
    "            # Ensure conversion to float32 arrays for Vector Search compatibility\n",
    "            import numpy as np\n",
    "            validated = pd.Series([np.array(vec, dtype=np.float32).tolist() for vec in all_embeddings])\n",
    "            yield validated\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ UDF embedding failure: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "print(\"✅ Embedding UDF defined successfully\")\n",
    "print(\"\uD83D\uDCA1 This UDF will be applied to the text column in the next step\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c043dc66-9ff2-4ad9-8b1f-05e3cec9d441",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDCBE Step 7: Apply Embeddings and Save to Delta\n",
    "\n",
    "Now we'll apply our embedding UDF to the chunked text and save the results. This creates a table where each chunk has both its original text and its vector embedding.\n",
    "\n",
    "### \uD83C\uDFAF What This Step Does:\n",
    "\n",
    "1. **Loads the chunked data** from our Delta table\n",
    "2. **Applies the embedding UDF** to generate vectors for each chunk\n",
    "3. **Adds an embedding column** to the DataFrame\n",
    "4. **Saves the enriched data** back to Delta Lake\n",
    "\n",
    "### \uD83D\uDCCA Resulting Schema:\n",
    "\n",
    "After this step, each row will contain:\n",
    "- `source`: Document origin (cdc_faq or who_guidelines)\n",
    "- `chunk_id`: Sequential identifier\n",
    "- `text`: The actual text content\n",
    "- `embedding`: 1024-dimensional vector (array of floats)\n",
    "\n",
    "### ⚡ Performance Notes:\n",
    "\n",
    "- Processing time depends on the number of chunks and endpoint capacity\n",
    "- The UDF processes data in parallel across Spark partitions\n",
    "- Monitor the embedding endpoint for any throttling or errors\n",
    "- For large datasets, consider increasing endpoint capacity\n",
    "\n",
    "### \uD83D\uDCA1 Why Save Embeddings:\n",
    "\n",
    "Storing embeddings separately allows us to:\n",
    "- **Reuse embeddings** without regenerating them\n",
    "- **Version control** embedding changes\n",
    "- **Analyze embedding quality** through inspection\n",
    "- **Support multiple indexes** from the same embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "179c7e83-7422-402b-a509-c586916dec29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load chunks from previous step\n",
    "chunk_df = spark.read.format(\"delta\").load(\"/tmp/rag_chunks\")\n",
    "\n",
    "print(f\"\uD83D\uDCCA Loaded {chunk_df.count()} chunks from Delta table\")\n",
    "print(\"\uD83D\uDD04 Generating embeddings... (this may take a few minutes)\")\n",
    "\n",
    "# Apply embedding UDF to generate vectors\n",
    "embedded_df = chunk_df.withColumn(\"embedding\", get_embeddings_udf(\"text\"))\n",
    "\n",
    "print(\"✅ Embeddings generated successfully\")\n",
    "\n",
    "# Save to new Delta location\n",
    "embedded_df.write.mode(\"overwrite\").format(\"delta\").save(\"/tmp/rag_chunks_embedded\")\n",
    "\n",
    "print(f\"✅ Embedded chunks saved at /tmp/rag_chunks_embedded\")\n",
    "print(f\"\uD83D\uDCA1 Each chunk now has a 1024-dimensional embedding vector\")\n",
    "\n",
    "# Display sample to verify\n",
    "print(\"\\n\uD83D\uDCCB Sample of embedded data:\")\n",
    "embedded_df.select(\"source\", \"chunk_id\", \"text\").show(3, truncate=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4445abb5-714e-496f-9e01-f35b77159860",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83E\uDDED Step 8: Create a Vector Search Endpoint\n",
    "\n",
    "Before we can create a vector search index, we need a **Vector Search endpoint**. This is the compute infrastructure that will serve our similarity search queries.\n",
    "\n",
    "### \uD83C\uDFAF What is a Vector Search Endpoint?\n",
    "\n",
    "A Vector Search endpoint is:\n",
    "- **Managed infrastructure** for hosting vector indexes\n",
    "- **Auto-scaling compute** that handles query load\n",
    "- **Optimized for similarity search** using approximate nearest neighbor algorithms\n",
    "- **Integrated with Unity Catalog** for governance and access control\n",
    "\n",
    "### \uD83D\uDD27 Endpoint Types:\n",
    "\n",
    "1. **STANDARD**: General-purpose, good for most use cases\n",
    "2. **STORAGE_OPTIMIZED**: Better for very large indexes (millions of vectors)\n",
    "\n",
    "For this lab, we're using **STANDARD** which is suitable for our document collection size.\n",
    "\n",
    "### ⚡ Endpoint Lifecycle:\n",
    "\n",
    "- **Creating**: Endpoint is being provisioned\n",
    "- **ONLINE**: Ready to serve queries\n",
    "- **OFFLINE**: Temporarily unavailable\n",
    "- **FAILED**: Provisioning failed (check logs)\n",
    "\n",
    "### \uD83D\uDCA1 Production Considerations:\n",
    "\n",
    "- **Budget policies**: Set spending limits to control costs\n",
    "- **Access control**: Use ACLs to manage who can query the endpoint\n",
    "- **Monitoring**: Track query latency and throughput\n",
    "- **High availability**: Consider multiple endpoints for critical applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "032af985-98b5-4120-bd16-9978e8a61367",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "import time\n",
    "\n",
    "VECTOR_SEARCH_ENDPOINT_NAME = \"orielly-chapter2-endpoint\"\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "def endpoint_exists(vsc, endpoint_name):\n",
    "    \"\"\"Check if a vector search endpoint already exists.\"\"\"\n",
    "    try:\n",
    "        vsc.get_endpoint(endpoint_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        if \"NOT_FOUND\" in str(e) or \"does not exist\" in str(e):\n",
    "            return False\n",
    "        raise e\n",
    "\n",
    "def wait_for_vs_endpoint_to_be_ready(vsc, endpoint_name, timeout=700, poll_interval=15):\n",
    "    \"\"\"Wait for vector search endpoint to become ONLINE.\"\"\"\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            status = vsc.get_endpoint(endpoint_name).get(\"endpoint_status\", {}).get(\"state\", \"\")\n",
    "            print(f\"⏳ Endpoint status: {status}\")\n",
    "            if status == \"ONLINE\":\n",
    "                print(f\"✅ Vector Search endpoint '{endpoint_name}' is ready.\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to get endpoint status: {e}\")\n",
    "\n",
    "        if time.time() - start_time > timeout:\n",
    "            raise TimeoutError(f\"❌ Timeout: Endpoint '{endpoint_name}' was not ready after {timeout} seconds.\")\n",
    "        time.sleep(poll_interval)\n",
    "\n",
    "# Create endpoint if it doesn't exist\n",
    "if not endpoint_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME):\n",
    "    print(f\"\uD83D\uDE80 Creating Vector Search endpoint: {VECTOR_SEARCH_ENDPOINT_NAME}\")\n",
    "    vsc.create_endpoint(name=VECTOR_SEARCH_ENDPOINT_NAME, endpoint_type=\"STANDARD\")\n",
    "    time.sleep(5)  # Allow time for provisioning to start\n",
    "else:\n",
    "    print(f\"ℹ️ Vector Search endpoint '{VECTOR_SEARCH_ENDPOINT_NAME}' already exists.\")\n",
    "\n",
    "# Wait for endpoint to be ready\n",
    "wait_for_vs_endpoint_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a962c87-3a7b-4d13-867b-61cc2f058e67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDDC2️ Step 8.1: Register Embedded Delta Table\n",
    "\n",
    "To enable querying and integration with Vector Search, we'll register our embedded chunks as a managed table in Unity Catalog.\n",
    "\n",
    "### \uD83C\uDFAF Why Register as a Table?\n",
    "\n",
    "Registering the Delta data as a table provides:\n",
    "- **SQL access**: Query embeddings using standard SQL\n",
    "- **Governance**: Unity Catalog tracks lineage and access\n",
    "- **Discoverability**: Other users can find and use the data\n",
    "- **Integration**: Seamless connection with Vector Search\n",
    "\n",
    "### \uD83D\uDCCB Table Location:\n",
    "\n",
    "We're registering the table as: `main.default.rag_chunks_embedded`\n",
    "- **Catalog**: `main` (default Unity Catalog)\n",
    "- **Schema**: `default` (default schema)\n",
    "- **Table**: `rag_chunks_embedded` (our embedded chunks)\n",
    "\n",
    "### \uD83D\uDCA1 Best Practices:\n",
    "\n",
    "In production, you would:\n",
    "- Use a dedicated catalog for RAG data\n",
    "- Create schemas by project or domain\n",
    "- Apply appropriate access controls\n",
    "- Document table purpose and schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7010179f-98e3-4f6d-a0b7-69b37f0f6d06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register embedded chunks as a managed table\n",
    "print(\"\uD83D\uDCDD Registering embedded chunks as Unity Catalog table...\")\n",
    "\n",
    "spark.read.format(\"delta\").load(\"/tmp/rag_chunks_embedded\").write.mode(\"overwrite\").saveAsTable(\"main.default.rag_chunks_embedded\")\n",
    "\n",
    "print(\"✅ Table registered as: main.default.rag_chunks_embedded\")\n",
    "print(\"\uD83D\uDCA1 You can now query this table using SQL or DataFrame API\")\n",
    "\n",
    "# Verify registration\n",
    "table_info = spark.sql(\"DESCRIBE EXTENDED main.default.rag_chunks_embedded\")\n",
    "print(\"\\n\uD83D\uDCCA Table schema:\")\n",
    "table_info.select(\"col_name\", \"data_type\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "397c0105-cc01-4ff3-b703-cef02da527de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83E\uDDE0 Step 9: Create and Sync a Vector Search Index\n",
    "\n",
    "Now we'll create the actual vector search index that will enable fast similarity-based retrieval. This is where all our preparation comes together!\n",
    "\n",
    "### \uD83C\uDFAF What is a Vector Search Index?\n",
    "\n",
    "A vector search index is a specialized data structure that:\n",
    "- **Stores vector embeddings** in an optimized format\n",
    "- **Enables fast similarity search** using approximate nearest neighbor (ANN) algorithms\n",
    "- **Automatically syncs** with the source Delta table (for Delta Sync indexes)\n",
    "- **Scales efficiently** to millions of vectors\n",
    "\n",
    "### \uD83D\uDD27 Index Configuration:\n",
    "\n",
    "We're creating a **Delta Sync Index** with these parameters:\n",
    "- **endpoint_name**: The vector search endpoint we created earlier\n",
    "- **index_name**: Full three-level name (catalog.schema.index)\n",
    "- **source_table_name**: The Delta table containing our embeddings\n",
    "- **pipeline_type**: `TRIGGERED` (manual sync) vs `CONTINUOUS` (auto-sync)\n",
    "- **primary_key**: Unique identifier for each chunk\n",
    "- **embedding_source_column**: Text column to embed\n",
    "- **embedding_model_endpoint_name**: Model to use for embedding\n",
    "\n",
    "### \uD83D\uDCCA Delta Sync vs Direct Access:\n",
    "\n",
    "**Delta Sync Index** (what we're using):\n",
    "- ✅ Automatically syncs with source table\n",
    "- ✅ Handles incremental updates efficiently\n",
    "- ✅ Easier to manage and maintain\n",
    "- ✅ Best for most use cases\n",
    "\n",
    "**Direct Access Index**:\n",
    "- Manual updates via API\n",
    "- More control over index content\n",
    "- Useful for custom workflows\n",
    "\n",
    "### ⚡ Sync Modes:\n",
    "\n",
    "**TRIGGERED** (what we're using):\n",
    "- Manual sync via API or UI\n",
    "- Lower cost (no continuous compute)\n",
    "- Good for batch updates\n",
    "- Sync on-demand when data changes\n",
    "\n",
    "**CONTINUOUS**:\n",
    "- Auto-syncs within seconds\n",
    "- Higher cost (dedicated compute)\n",
    "- Best for real-time applications\n",
    "- Requires Change Data Feed enabled\n",
    "\n",
    "### \uD83D\uDCA1 Change Data Feed (CDF):\n",
    "\n",
    "We enable CDF on the source table to track changes:\n",
    "- Captures inserts, updates, and deletes\n",
    "- Enables incremental sync (only process changes)\n",
    "- Required for Delta Sync indexes\n",
    "- Minimal storage overhead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52e2c123-cc42-419d-8be5-3281b975ac1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "catalog = \"main\"\n",
    "schema = \"default\"\n",
    "table = \"rag_chunks_embedded\"\n",
    "index = \"rag_chunks_index\"\n",
    "\n",
    "VECTOR_SEARCH_ENDPOINT_NAME = \"orielly-chapter2-endpoint\"\n",
    "EMBEDDING_ENDPOINT_NAME = \"databricks-bge-large-en\"\n",
    "\n",
    "source_table_fullname = f\"{catalog}.{schema}.{table}\"\n",
    "vs_index_fullname = f\"{catalog}.{schema}.{index}\"\n",
    "\n",
    "# Initialize Vector Search Client\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "# Enable Change Data Feed (required for Delta Sync)\n",
    "print(\"\uD83D\uDD27 Enabling Change Data Feed on source table...\")\n",
    "try:\n",
    "    spark.sql(f\"ALTER TABLE {source_table_fullname} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
    "    print(f\"✅ CDF enabled on {source_table_fullname}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not enable CDF (may already be enabled): {e}\")\n",
    "\n",
    "# Check if index already exists\n",
    "def index_exists(vsc, endpoint, index_name):\n",
    "    \"\"\"Check if a vector search index already exists.\"\"\"\n",
    "    try:\n",
    "        vsc.get_index(endpoint_name=endpoint, index_name=index_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        if \"NOT_FOUND\" in str(e) or \"does not exist\" in str(e):\n",
    "            return False\n",
    "        raise e\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if not index_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname):\n",
    "    print(f\"\uD83D\uDE80 Creating index {vs_index_fullname} on endpoint {VECTOR_SEARCH_ENDPOINT_NAME}...\")\n",
    "    vsc.create_delta_sync_index(\n",
    "        endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,\n",
    "        index_name=vs_index_fullname,\n",
    "        source_table_name=source_table_fullname,\n",
    "        pipeline_type=\"TRIGGERED\",  # Manual sync mode\n",
    "        primary_key=\"chunk_id\",     # Unique identifier for each chunk\n",
    "        embedding_source_column=\"text\",  # Column with text to embed\n",
    "        embedding_model_endpoint_name=EMBEDDING_ENDPOINT_NAME  # Embedding model to use\n",
    "    )\n",
    "    print(\"✅ Index created successfully\")\n",
    "else:\n",
    "    print(f\"ℹ️ Index {vs_index_fullname} already exists\")\n",
    "\n",
    "# Wait until index is ready\n",
    "print(f\"⏳ Waiting for index {vs_index_fullname} to be ready...\")\n",
    "index_obj = vsc.get_index(endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME, index_name=vs_index_fullname)\n",
    "index_obj.wait_until_ready()\n",
    "print(f\"✅ Index '{vs_index_fullname}' is ready for queries\")\n",
    "\n",
    "# Manually sync the index\n",
    "print(f\"\uD83D\uDD04 Syncing index with latest data...\")\n",
    "index_obj.sync()\n",
    "print(f\"✅ Index {vs_index_fullname} synced successfully\")\n",
    "print(f\"\uD83D\uDCA1 The index is now ready for semantic search queries!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c1c2f1a-3a8c-4008-b8ae-61354c32d034",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDD0D Step 10: Perform Semantic Search Queries\n",
    "\n",
    "Now for the exciting part - let's query our vector search index using natural language! This demonstrates the power of semantic search in RAG systems.\n",
    "\n",
    "### \uD83C\uDFAF How Semantic Search Works:\n",
    "\n",
    "1. **User asks a question** in natural language\n",
    "2. **Question is embedded** using the same model as our chunks\n",
    "3. **Vector similarity** is computed between question and all chunks\n",
    "4. **Top-k most similar chunks** are returned\n",
    "5. **Results are ranked** by similarity score\n",
    "\n",
    "### \uD83D\uDD27 Query Parameters:\n",
    "\n",
    "- **query_text**: The natural language question\n",
    "- **columns**: Which columns to return from the index\n",
    "- **num_results**: How many top results to retrieve (k)\n",
    "\n",
    "### \uD83D\uDCCA Understanding Results:\n",
    "\n",
    "Each result contains:\n",
    "- **chunk_id**: Unique identifier\n",
    "- **source**: Which document it came from\n",
    "- **text**: The actual chunk content\n",
    "- **score**: Similarity score (higher = more relevant)\n",
    "\n",
    "### \uD83D\uDCA1 Query Tips:\n",
    "\n",
    "- **Be specific**: \"What are COVID-19 symptoms?\" vs \"COVID\"\n",
    "- **Use natural language**: Write like you're asking a person\n",
    "- **Adjust num_results**: More results = better coverage, but may include less relevant chunks\n",
    "- **Check sources**: Verify which documents are being retrieved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49fa44fb-20c5-47a1-b534-f53237475748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "# Example question for RAG\n",
    "question = \"What are the symptoms of COVID-19?\"\n",
    "\n",
    "# Define index location\n",
    "catalog = \"main\"\n",
    "schema = \"default\"\n",
    "index = \"rag_chunks_index\"\n",
    "\n",
    "VECTOR_SEARCH_ENDPOINT_NAME = \"orielly-chapter2-endpoint\"\n",
    "vs_index_fullname = f\"{catalog}.{schema}.{index}\"\n",
    "\n",
    "# Initialize client\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "print(f\"\uD83D\uDD0D Searching for: '{question}'\")\n",
    "print(f\"\uD83D\uDCCA Retrieving top 5 most relevant chunks...\\n\")\n",
    "\n",
    "# Perform similarity search\n",
    "results = vsc.get_index(\n",
    "    endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,\n",
    "    index_name=vs_index_fullname\n",
    ").similarity_search(\n",
    "    query_text=question,\n",
    "    columns=[\"chunk_id\", \"source\", \"text\"],\n",
    "    num_results=5\n",
    ")\n",
    "\n",
    "# Extract and display results\n",
    "docs = results.get(\"result\", {}).get(\"data_array\", [])\n",
    "\n",
    "if not docs:\n",
    "    print(\"❌ No results found. Check if the index is properly synced.\")\n",
    "else:\n",
    "    print(f\"✅ Found {len(docs)} relevant chunks:\\n\")\n",
    "    for i, row in enumerate(docs, start=1):\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"\uD83D\uDD39 Result {i}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"\uD83D\uDCC4 Source: {row[1]}\")\n",
    "        print(f\"\uD83C\uDD94 Chunk ID: {row[0]}\")\n",
    "        print(f\"\uD83D\uDCDD Text:\\n{row[2][:300]}...\")  # Show first 300 characters\n",
    "        print()\n",
    "\n",
    "print(\"\uD83D\uDCA1 These chunks would be passed to an LLM to generate the final answer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d816628f-e7bc-4c5d-8546-a62261a5784a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDD00 Step 11: Compare Retrieval With and Without Chunk Overlap\n",
    "\n",
    "One of the key objectives of this lab is to understand how chunk overlap affects retrieval quality. Let's create chunks **without overlap** and compare the results!\n",
    "\n",
    "### \uD83C\uDFAF Experiment Design:\n",
    "\n",
    "We'll create two sets of chunks from the same documents:\n",
    "1. **Without overlap** (overlap=0) - Chunks are completely independent\n",
    "2. **With overlap** (overlap=50) - Chunks share 50 words with neighbors\n",
    "\n",
    "Then we'll query both indexes with the same question and compare:\n",
    "- **Precision**: Are the retrieved chunks relevant?\n",
    "- **Completeness**: Do we get the full context needed to answer?\n",
    "- **Redundancy**: How much duplicate information is retrieved?\n",
    "\n",
    "### \uD83D\uDCCA Why This Matters:\n",
    "\n",
    "Overlap is a critical design decision in RAG systems:\n",
    "- **Too little overlap**: Risk losing context at chunk boundaries\n",
    "- **Too much overlap**: Increased storage and redundant retrieval\n",
    "- **Optimal overlap**: Balances context preservation with efficiency\n",
    "\n",
    "### \uD83D\uDD2C What We're Testing:\n",
    "\n",
    "Consider a query like: \"What is the recommended isolation period?\"\n",
    "\n",
    "**Without overlap**, the answer might be split:\n",
    "- Chunk A: \"...patients should isolate for 5 days.\"\n",
    "- Chunk B: \"After isolation, wear a mask for 5 additional days.\"\n",
    "\n",
    "**With overlap**, both chunks contain the complete context:\n",
    "- Chunk A: \"...patients should isolate for 5 days. After isolation, wear...\"\n",
    "- Chunk B: \"...isolate for 5 days. After isolation, wear a mask for 5 additional days.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a2e6603-77b6-4a40-9580-0797f4eeeb3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "print(\"\uD83D\uDD2C Creating chunks WITHOUT overlap for comparison...\")\n",
    "\n",
    "# Load the same cleaned text\n",
    "with open(\"/dbfs/FileStore/rag_docs/cdc_faq_clean.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cdc_text = f.read()\n",
    "\n",
    "with open(\"/dbfs/FileStore/rag_docs/who_guidelines_clean.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    who_text = f.read()\n",
    "\n",
    "documents = [\n",
    "    {\"source\": \"cdc_faq\", \"text\": cdc_text},\n",
    "    {\"source\": \"who_guidelines\", \"text\": who_text}\n",
    "]\n",
    "\n",
    "# Create chunks WITHOUT overlap (overlap=0)\n",
    "all_chunks_no_overlap = []\n",
    "for doc in documents:\n",
    "    chunks = chunk_text(doc[\"text\"], chunk_size=200, overlap=0)  # No overlap!\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        all_chunks_no_overlap.append({\n",
    "            \"source\": doc[\"source\"],\n",
    "            \"chunk_id\": i,\n",
    "            \"text\": chunk\n",
    "        })\n",
    "\n",
    "print(f\"\uD83D\uDCCA Chunks WITHOUT overlap: {len(all_chunks_no_overlap)}\")\n",
    "\n",
    "# Save to Delta\n",
    "chunk_df_no_overlap = pd.DataFrame(all_chunks_no_overlap)\n",
    "spark_df_no_overlap = spark.createDataFrame(chunk_df_no_overlap)\n",
    "spark_df_no_overlap.write.mode(\"overwrite\").format(\"delta\").save(\"/tmp/rag_chunks_no_overlap\")\n",
    "\n",
    "print(\"✅ No-overlap chunks saved to Delta\")\n",
    "\n",
    "# Generate embeddings for no-overlap chunks\n",
    "print(\"\uD83D\uDD04 Generating embeddings for no-overlap chunks...\")\n",
    "chunk_df_loaded = spark.read.format(\"delta\").load(\"/tmp/rag_chunks_no_overlap\")\n",
    "embedded_df_no_overlap = chunk_df_loaded.withColumn(\"embedding\", get_embeddings_udf(\"text\"))\n",
    "embedded_df_no_overlap.write.mode(\"overwrite\").format(\"delta\").save(\"/tmp/rag_chunks_no_overlap_embedded\")\n",
    "\n",
    "print(\"✅ No-overlap chunks embedded and saved\")\n",
    "\n",
    "# Register as table\n",
    "spark.read.format(\"delta\").load(\"/tmp/rag_chunks_no_overlap_embedded\").write.mode(\"overwrite\").saveAsTable(\"main.default.rag_chunks_no_overlap_embedded\")\n",
    "\n",
    "print(\"✅ Table registered: main.default.rag_chunks_no_overlap_embedded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "294a3c4d-555f-48f1-a36a-3cbc5bfed8ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDCCA Step 11.1: Create Index for No-Overlap Chunks\n",
    "\n",
    "Now let's create a separate vector search index for the no-overlap chunks so we can compare retrieval results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08ff8112-4563-457e-9cc4-ee6ee34289cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "# Configuration for no-overlap index\n",
    "catalog = \"main\"\n",
    "schema = \"default\"\n",
    "table_no_overlap = \"rag_chunks_no_overlap_embedded\"\n",
    "index_no_overlap = \"rag_chunks_no_overlap_index\"\n",
    "\n",
    "VECTOR_SEARCH_ENDPOINT_NAME = \"orielly-chapter2-endpoint\"\n",
    "EMBEDDING_ENDPOINT_NAME = \"databricks-bge-large-en\"\n",
    "\n",
    "source_table_no_overlap = f\"{catalog}.{schema}.{table_no_overlap}\"\n",
    "vs_index_no_overlap = f\"{catalog}.{schema}.{index_no_overlap}\"\n",
    "\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "# Enable CDF\n",
    "print(\"\uD83D\uDD27 Enabling CDF on no-overlap table...\")\n",
    "try:\n",
    "    spark.sql(f\"ALTER TABLE {source_table_no_overlap} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
    "    print(\"✅ CDF enabled\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ CDF may already be enabled: {e}\")\n",
    "\n",
    "# Create index\n",
    "if not index_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_no_overlap):\n",
    "    print(f\"\uD83D\uDE80 Creating no-overlap index...\")\n",
    "    vsc.create_delta_sync_index(\n",
    "        endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,\n",
    "        index_name=vs_index_no_overlap,\n",
    "        source_table_name=source_table_no_overlap,\n",
    "        pipeline_type=\"TRIGGERED\",\n",
    "        primary_key=\"chunk_id\",\n",
    "        embedding_source_column=\"text\",\n",
    "        embedding_model_endpoint_name=EMBEDDING_ENDPOINT_NAME\n",
    "    )\n",
    "    print(\"✅ No-overlap index created\")\n",
    "else:\n",
    "    print(f\"ℹ️ No-overlap index already exists\")\n",
    "\n",
    "# Wait and sync\n",
    "print(\"⏳ Waiting for no-overlap index to be ready...\")\n",
    "index_obj_no_overlap = vsc.get_index(endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME, index_name=vs_index_no_overlap)\n",
    "index_obj_no_overlap.wait_until_ready()\n",
    "print(\"✅ No-overlap index ready\")\n",
    "\n",
    "index_obj_no_overlap.sync()\n",
    "print(\"✅ No-overlap index synced\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8e46add-da8d-4ee4-8e7f-a7ce9515af26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDD0D Step 11.2: Compare Retrieval Results\n",
    "\n",
    "Now let's query both indexes with the same question and compare the results!\n",
    "\n",
    "### \uD83C\uDFAF Comparison Metrics:\n",
    "\n",
    "1. **Relevance**: Do the chunks contain information relevant to the query?\n",
    "2. **Completeness**: Is the full answer present in the retrieved chunks?\n",
    "3. **Context Quality**: Do chunks have enough surrounding context?\n",
    "4. **Redundancy**: How much information is duplicated across chunks?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93e29169-027a-472f-9389-9923a3fa8b67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "import pandas as pd\n",
    "\n",
    "# Test question\n",
    "test_question = \"What is the recommended isolation period for COVID-19?\"\n",
    "\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "print(f\"\uD83D\uDD0D Query: '{test_question}'\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"\uD83D\uDCCA COMPARISON: WITH OVERLAP vs WITHOUT OVERLAP\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Query WITH overlap index\n",
    "print(\"\uD83D\uDD39 Results WITH OVERLAP (50 words):\")\n",
    "print(\"-\" * 80)\n",
    "results_with_overlap = vsc.get_index(\n",
    "    endpoint_name=\"orielly-chapter2-endpoint\",\n",
    "    index_name=\"main.default.rag_chunks_index\"\n",
    ").similarity_search(\n",
    "    query_text=test_question,\n",
    "    columns=[\"chunk_id\", \"source\", \"text\"],\n",
    "    num_results=3\n",
    ")\n",
    "\n",
    "docs_with_overlap = results_with_overlap.get(\"result\", {}).get(\"data_array\", [])\n",
    "for i, row in enumerate(docs_with_overlap, start=1):\n",
    "    print(f\"\\nResult {i} (Chunk ID: {row[0]}, Source: {row[1]}):\")\n",
    "    print(f\"{row[2][:200]}...\")\n",
    "\n",
    "# Query WITHOUT overlap index\n",
    "print(f\"\\n\\n\uD83D\uDD39 Results WITHOUT OVERLAP:\")\n",
    "print(\"-\" * 80)\n",
    "results_no_overlap = vsc.get_index(\n",
    "    endpoint_name=\"orielly-chapter2-endpoint\",\n",
    "    index_name=\"main.default.rag_chunks_no_overlap_index\"\n",
    ").similarity_search(\n",
    "    query_text=test_question,\n",
    "    columns=[\"chunk_id\", \"source\", \"text\"],\n",
    "    num_results=3\n",
    ")\n",
    "\n",
    "docs_no_overlap = results_no_overlap.get(\"result\", {}).get(\"data_array\", [])\n",
    "for i, row in enumerate(docs_no_overlap, start=1):\n",
    "    print(f\"\\nResult {i} (Chunk ID: {row[0]}, Source: {row[1]}):\")\n",
    "    print(f\"{row[2][:200]}...\")\n",
    "\n",
    "# Analysis\n",
    "print(f\"\\n\\n{'='*80}\")\n",
    "print(\"\uD83D\uDCC8 ANALYSIS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Calculate average chunk length\n",
    "avg_len_with = sum(len(row[2]) for row in docs_with_overlap) / len(docs_with_overlap) if docs_with_overlap else 0\n",
    "avg_len_without = sum(len(row[2]) for row in docs_no_overlap) / len(docs_no_overlap) if docs_no_overlap else 0\n",
    "\n",
    "print(f\"Average chunk length WITH overlap: {avg_len_with:.0f} characters\")\n",
    "print(f\"Average chunk length WITHOUT overlap: {avg_len_without:.0f} characters\")\n",
    "\n",
    "# Check for keyword presence (simple relevance proxy)\n",
    "keyword = \"isolation\"\n",
    "with_overlap_hits = sum(1 for row in docs_with_overlap if keyword.lower() in row[2].lower())\n",
    "without_overlap_hits = sum(1 for row in docs_no_overlap if keyword.lower() in row[2].lower())\n",
    "\n",
    "print(f\"\\nChunks containing '{keyword}':\")\n",
    "print(f\"  WITH overlap: {with_overlap_hits}/{len(docs_with_overlap)}\")\n",
    "print(f\"  WITHOUT overlap: {without_overlap_hits}/{len(docs_no_overlap)}\")\n",
    "\n",
    "print(f\"\\n\uD83D\uDCA1 Key Observations:\")\n",
    "print(f\"   • WITH overlap chunks tend to have more context around key information\")\n",
    "print(f\"   • WITHOUT overlap may miss context if answer spans chunk boundaries\")\n",
    "print(f\"   • Overlap increases redundancy but improves answer completeness\")\n",
    "print(f\"   • The optimal overlap depends on your specific use case and query patterns\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82b3c629-f8c7-4849-950e-d0c74dcb3085",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDCCF Step 12: Evaluate Chunk Size Effects on Retrieval Precision\n",
    "\n",
    "Now let's analyze how different chunk sizes affect retrieval precision. This helps us understand the trade-offs between chunk granularity and retrieval quality.\n",
    "\n",
    "### \uD83C\uDFAF What We're Measuring:\n",
    "\n",
    "We'll simulate different chunk sizes and measure:\n",
    "- **Match score**: How many retrieved chunks contain relevant keywords\n",
    "- **Precision proxy**: Ratio of relevant chunks to total retrieved\n",
    "- **Coverage**: Whether smaller or larger chunks capture the answer better\n",
    "\n",
    "### \uD83D\uDCCA Chunk Sizes to Test:\n",
    "\n",
    "- **50 words**: Very small, highly focused chunks\n",
    "- **150 words**: Medium-small chunks\n",
    "- **300 words**: Medium-large chunks (close to our 200-word baseline)\n",
    "- **600 words**: Large chunks with extensive context\n",
    "\n",
    "### \uD83D\uDD0D Expected Patterns:\n",
    "\n",
    "- **Very small chunks (50)**: May be too fragmented, missing context\n",
    "- **Medium chunks (150-300)**: Often optimal for focused retrieval\n",
    "- **Large chunks (600)**: More context but may dilute precision\n",
    "\n",
    "### \uD83D\uDCA1 Why This Analysis Matters:\n",
    "\n",
    "In production RAG systems, chunk size directly impacts:\n",
    "- **Retrieval precision**: Smaller chunks = more focused matches\n",
    "- **Answer completeness**: Larger chunks = more context\n",
    "- **Storage costs**: More chunks = higher storage and compute\n",
    "- **LLM context usage**: Larger chunks consume more tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c35736-4de0-4d70-942b-3a35e49dec70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chunk sizes to evaluate\n",
    "chunk_sizes = [50, 150, 300, 600]\n",
    "precision_simulation = []\n",
    "\n",
    "# Test question\n",
    "question = \"What is the isolation protocol?\"\n",
    "\n",
    "# Retrieve once from the main index\n",
    "top_k = 10\n",
    "print(f\"\uD83D\uDD0D Evaluating chunk size impact for query: '{question}'\")\n",
    "print(f\"\uD83D\uDCCA Retrieving top {top_k} chunks from index...\\n\")\n",
    "\n",
    "results = vsc.get_index(\n",
    "    endpoint_name=\"orielly-chapter2-endpoint\",\n",
    "    index_name=\"main.default.rag_chunks_index\"\n",
    ").similarity_search(\n",
    "    query_text=question,\n",
    "    columns=[\"chunk_id\", \"source\", \"text\"],\n",
    "    num_results=top_k\n",
    ")\n",
    "\n",
    "retrieved = results.get(\"result\", {}).get(\"data_array\", [])\n",
    "\n",
    "# Simulate precision for different chunk sizes\n",
    "print(\"\uD83D\uDCC8 Analyzing retrieval precision by chunk size...\\n\")\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    # Filter chunks that would fit in this size (approximate)\n",
    "    # We're simulating by filtering retrieved chunks by length\n",
    "    filtered_chunks = [row for row in retrieved if len(row[2].split()) <= size + 25]\n",
    "    filtered_k = len(filtered_chunks)\n",
    "\n",
    "    if filtered_k == 0:\n",
    "        precision_score = 0\n",
    "        comment = \"No chunks match this size\"\n",
    "    else:\n",
    "        # Calculate precision: how many contain the keyword \"isolation\"\n",
    "        precision_score = sum([\"isolation\" in row[2].lower() for row in filtered_chunks]) / filtered_k\n",
    "        comment = f\"{filtered_k} chunks analyzed\"\n",
    "\n",
    "    precision_simulation.append({\n",
    "        \"Chunk Size (words)\": size,\n",
    "        \"Chunks Retrieved\": filtered_k,\n",
    "        \"Precision Score\": precision_score,\n",
    "        \"Notes\": comment\n",
    "    })\n",
    "\n",
    "    print(f\"Chunk size {size:3d} words: Precision = {precision_score:.2f} ({comment})\")\n",
    "\n",
    "# Create DataFrame and visualize\n",
    "df_eval = pd.DataFrame(precision_simulation)\n",
    "\n",
    "print(f\"\\n\uD83D\uDCCA Precision Analysis Summary:\")\n",
    "print(\"=\"*80)\n",
    "display(df_eval)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_eval[\"Chunk Size (words)\"], df_eval[\"Precision Score\"], marker=\"o\", linewidth=2, markersize=8)\n",
    "plt.title(\"Retrieval Precision by Chunk Size\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Chunk Size (words)\", fontsize=12)\n",
    "plt.ylabel(\"Precision Score\", fontsize=12)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='50% threshold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n\uD83D\uDCA1 Interpretation:\")\n",
    "print(f\"   • The optimal chunk size balances precision and context\")\n",
    "print(f\"   • Very small chunks may lack sufficient context\")\n",
    "print(f\"   • Very large chunks may dilute relevance with noise\")\n",
    "print(f\"   • Medium-sized chunks (150-300 words) often perform best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55ede93e-71f0-44e1-9b26-21d6d8ded0d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDCCA Understanding Precision by Chunk Size\n",
    "\n",
    "This analysis reveals critical insights about chunk granularity in RAG systems.\n",
    "\n",
    "### \uD83D\uDCC8 Key Findings:\n",
    "\n",
    "1. **Very Small Chunks (50 words)**:\n",
    "   - ❌ Often too fragmented to capture complete thoughts\n",
    "   - ❌ May miss context needed for accurate retrieval\n",
    "   - ✅ Can be useful for very specific, keyword-focused queries\n",
    "\n",
    "2. **Medium Chunks (150-300 words)**:\n",
    "   - ✅ Typically optimal for most RAG applications\n",
    "   - ✅ Balance between focus and context\n",
    "   - ✅ Align well with typical question scope\n",
    "   - ✅ Efficient use of LLM context window\n",
    "\n",
    "3. **Large Chunks (600+ words)**:\n",
    "   - ✅ Provide extensive context\n",
    "   - ❌ May include irrelevant information (noise)\n",
    "   - ❌ Consume more LLM tokens\n",
    "   - ⚠️ Can reduce precision due to dilution\n",
    "\n",
    "### \uD83C\uDFAF Production Recommendations:\n",
    "\n",
    "- **Start with 150-300 words** as a baseline\n",
    "- **Test with your specific queries** to find optimal size\n",
    "- **Consider domain characteristics**: Technical docs may need larger chunks\n",
    "- **Monitor retrieval metrics** in production to tune over time\n",
    "- **Use overlap (25-50 words)** to preserve context at boundaries\n",
    "\n",
    "### \uD83D\uDD2C Advanced Considerations:\n",
    "\n",
    "- **Adaptive chunking**: Vary size based on document structure\n",
    "- **Semantic chunking**: Split at topic boundaries, not fixed sizes\n",
    "- **Hierarchical retrieval**: Use multiple chunk sizes in parallel\n",
    "- **Query-dependent sizing**: Adjust chunk size based on query type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe1a582a-cb38-48ea-a1da-ca4aa2a4410c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDD00 Step 13: Implement Hybrid Search Strategy\n",
    "\n",
    "While vector search is powerful, combining it with keyword search can improve robustness. Let's implement a hybrid approach!\n",
    "\n",
    "### \uD83C\uDFAF Why Hybrid Search?\n",
    "\n",
    "**Vector Search** (semantic):\n",
    "- ✅ Finds conceptually similar content\n",
    "- ✅ Handles paraphrasing and synonyms\n",
    "- ❌ May miss exact term matches\n",
    "- ❌ Can be affected by embedding quality\n",
    "\n",
    "**Keyword Search** (lexical):\n",
    "- ✅ Guarantees exact term matches\n",
    "- ✅ Fast and deterministic\n",
    "- ❌ Misses semantic similarity\n",
    "- ❌ Sensitive to exact wording\n",
    "\n",
    "**Hybrid Approach**:\n",
    "- ✅ Best of both worlds\n",
    "- ✅ Fallback mechanism for reliability\n",
    "- ✅ Can combine and rerank results\n",
    "- ✅ More robust to edge cases\n",
    "\n",
    "### \uD83D\uDD27 Implementation Strategy:\n",
    "\n",
    "1. **Try vector search first** (primary method)\n",
    "2. **Fall back to keyword search** if vector search fails or returns no results\n",
    "3. **Optionally combine results** from both methods with weighted scoring\n",
    "\n",
    "### \uD83D\uDCA1 Production Enhancements:\n",
    "\n",
    "- **Reciprocal Rank Fusion (RRF)**: Combine rankings from both methods\n",
    "- **Weighted scoring**: Adjust importance of semantic vs lexical match\n",
    "- **Query classification**: Route queries to best search method\n",
    "- **Result deduplication**: Remove overlapping chunks from combined results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "844ed980-79e4-4ddb-b2aa-778d8657d2c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def hybrid_search(query, k=5):\n",
    "    \"\"\"\n",
    "    Perform hybrid search combining vector and keyword approaches.\n",
    "\n",
    "    Args:\n",
    "        query (str): Search query\n",
    "        k (int): Number of results to return\n",
    "\n",
    "    Returns:\n",
    "        list: Search results (either from vector search or keyword fallback)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Primary: Vector search\n",
    "        print(\"\uD83D\uDD0D Attempting semantic vector search...\")\n",
    "        results = vsc.get_index(\n",
    "            endpoint_name=\"orielly-chapter2-endpoint\",\n",
    "            index_name=\"main.default.rag_chunks_index\"\n",
    "        ).similarity_search(\n",
    "            query_text=query,\n",
    "            columns=[\"chunk_id\", \"source\", \"text\"],\n",
    "            num_results=k\n",
    "        )\n",
    "        hits = results.get(\"result\", {}).get(\"data_array\", [])\n",
    "\n",
    "        if hits:\n",
    "            print(f\"✅ Vector search returned {len(hits)} results\")\n",
    "            return hits\n",
    "        else:\n",
    "            print(\"⚠️ Vector search returned no results\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Vector search failed: {str(e)}\")\n",
    "\n",
    "    # Fallback: Keyword search using Spark SQL\n",
    "    print(\"\uD83D\uDD04 Falling back to keyword search...\")\n",
    "    query_terms = query.lower().split()\n",
    "\n",
    "    # Build SQL condition for keyword matching\n",
    "    condition = \" OR \".join([f\"LOWER(text) LIKE '%{term}%'\" for term in query_terms])\n",
    "\n",
    "    fallback_df = spark.sql(f\"\"\"\n",
    "        SELECT chunk_id, source, text\n",
    "        FROM main.default.rag_chunks_embedded\n",
    "        WHERE {condition}\n",
    "        LIMIT {k}\n",
    "    \"\"\")\n",
    "\n",
    "    results = fallback_df.collect()\n",
    "    print(f\"✅ Keyword search returned {len(results)} results\")\n",
    "    return results\n",
    "\n",
    "# Test hybrid search\n",
    "print(\"=\"*80)\n",
    "print(\"\uD83D\uDD2C Testing Hybrid Search\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_query = \"What are the symptoms of COVID-19?\"\n",
    "print(f\"\\nQuery: '{test_query}'\\n\")\n",
    "\n",
    "hybrid_results = hybrid_search(test_query, k=5)\n",
    "\n",
    "print(f\"\\n\uD83D\uDCCB Results:\")\n",
    "print(\"-\"*80)\n",
    "for i, r in enumerate(hybrid_results, start=1):\n",
    "    # Handle both tuple (from vector search) and Row (from SQL) formats\n",
    "    if isinstance(r, tuple):\n",
    "        chunk_id, source, text = r[0], r[1], r[2]\n",
    "    else:\n",
    "        chunk_id, source, text = r.chunk_id, r.source, r.text\n",
    "\n",
    "    print(f\"\\n\uD83D\uDD39 Result {i}:\")\n",
    "    print(f\"   Source: {source}\")\n",
    "    print(f\"   Chunk ID: {chunk_id}\")\n",
    "    print(f\"   Text: {text[:150]}...\")\n",
    "\n",
    "print(f\"\\n\uD83D\uDCA1 Hybrid search provides robustness by combining semantic and lexical matching\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "577c43c4-06ef-4df4-bb8c-1e96c0f57f94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83C\uDF93 Lab Wrap-Up: Key Learnings and Next Steps\n",
    "\n",
    "Congratulations! You've completed a comprehensive hands-on lab on chunking and indexing for RAG applications.\n",
    "\n",
    "### ✅ What You Accomplished:\n",
    "\n",
    "| Step | Achievement | Key Learning |\n",
    "|------|-------------|--------------|\n",
    "| \uD83D\uDCE5 **Document Ingestion** | Downloaded and extracted text from medical PDFs | Text extraction quality impacts downstream performance |\n",
    "| \uD83E\uDDF9 **Text Cleaning** | Removed noise and normalized formatting | Clean data = better embeddings and retrieval |\n",
    "| ✂️ **Chunking** | Applied sentence-based chunking with overlap | Overlap preserves context at chunk boundaries |\n",
    "| \uD83D\uDCBE **Delta Lake Storage** | Saved chunks with metadata in Delta format | Delta provides ACID guarantees and versioning |\n",
    "| \uD83E\uDDE0 **Embedding Generation** | Created vector embeddings using BGE model | Embeddings capture semantic meaning for similarity search |\n",
    "| \uD83D\uDD0D **Vector Search** | Built and queried vector search indexes | Enables fast semantic retrieval at scale |\n",
    "| \uD83D\uDD00 **Overlap Comparison** | Compared retrieval with/without overlap | Overlap improves completeness but adds redundancy |\n",
    "| \uD83D\uDCCF **Chunk Size Analysis** | Evaluated precision across different sizes | Medium chunks (150-300 words) often optimal |\n",
    "| \uD83D\uDD04 **Hybrid Search** | Combined semantic and keyword search | Hybrid approaches improve robustness |\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83E\uDDE0 Critical Insights:\n",
    "\n",
    "1. **Chunking Strategy Matters**:\n",
    "   - Chunk size directly impacts retrieval precision and recall\n",
    "   - Overlap prevents context loss at boundaries\n",
    "   - Sentence-based chunking preserves semantic coherence\n",
    "\n",
    "2. **Quality Over Quantity**:\n",
    "   - Clean, well-structured chunks outperform large volumes of noisy data\n",
    "   - Metadata (source, chunk_id) enables traceability and debugging\n",
    "   - Text preprocessing significantly improves embedding quality\n",
    "\n",
    "3. **Trade-offs Are Inevitable**:\n",
    "   - Smaller chunks = higher precision, but may lack context\n",
    "   - Larger chunks = more context, but lower precision\n",
    "   - More overlap = better completeness, but higher storage costs\n",
    "\n",
    "4. **Production Considerations**:\n",
    "   - Monitor retrieval metrics continuously\n",
    "   - A/B test different chunking strategies\n",
    "   - Consider domain-specific requirements\n",
    "   - Plan for incremental updates and versioning\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83D\uDE80 Next Steps and Extensions:\n",
    "\n",
    "1. **Complete the RAG Loop**:\n",
    "   - Connect retrieved chunks to an LLM endpoint (e.g., DBRX, Llama)\n",
    "   - Implement prompt engineering for answer generation\n",
    "   - Add citation and source attribution\n",
    "\n",
    "2. **Advanced Chunking**:\n",
    "   - Implement semantic chunking (split at topic boundaries)\n",
    "   - Try hierarchical chunking (multiple granularities)\n",
    "   - Experiment with document-aware chunking (preserve structure)\n",
    "\n",
    "3. **Retrieval Optimization**:\n",
    "   - Implement reranking with cross-encoders\n",
    "   - Add metadata filtering (date, source, category)\n",
    "   - Experiment with query expansion and reformulation\n",
    "\n",
    "4. **Evaluation and Monitoring**:\n",
    "   - Build evaluation datasets with ground truth\n",
    "   - Implement retrieval metrics (MRR, NDCG, Recall@k)\n",
    "   - Set up monitoring dashboards for production\n",
    "\n",
    "5. **Scale and Performance**:\n",
    "   - Test with larger document collections\n",
    "   - Optimize embedding batch sizes\n",
    "   - Implement caching for frequently accessed chunks\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83D\uDCDA Additional Resources:\n",
    "\n",
    "- **Databricks Documentation**: [Vector Search Guide](https://docs.databricks.com/en/vector-search/)\n",
    "- **Embedding Models**: Explore other models on Hugging Face\n",
    "- **RAG Patterns**: Study advanced RAG architectures (HyDE, RAG-Fusion)\n",
    "- **Evaluation**: Learn about RAGAS and other RAG evaluation frameworks\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83D\uDCAC Reflection Questions:\n",
    "\n",
    "1. How would you adapt this pipeline for a different domain (legal, financial, scientific)?\n",
    "2. What chunk size and overlap would you choose for your use case?\n",
    "3. How would you handle multilingual documents?\n",
    "4. What additional metadata would be valuable for your application?\n",
    "5. How would you evaluate retrieval quality in production?\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83C\uDFAF Final Thought:\n",
    "\n",
    "> **\"The quality of a RAG system is determined not by the sophistication of the LLM, but by the quality of the retrieved context. Master data preparation, and you master RAG.\"**\n",
    "\n",
    "Thank you for completing this lab! You now have the foundational skills to build production-grade RAG systems on Databricks.\n",
    "\n",
    "\uD83C\uDF1F **Happy Building!** \uD83C\uDF1F\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Orielly -Chapter 3- Chunking and Indexing for RAG",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}