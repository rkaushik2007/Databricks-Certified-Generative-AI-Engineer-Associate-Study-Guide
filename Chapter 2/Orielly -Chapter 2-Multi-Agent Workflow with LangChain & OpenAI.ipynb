{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e84da24d-0529-417d-bbcb-c00154e97cd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83E\uDDEA Hands-On Lab: Multi-Agent Workflow with LangChain in Databricks\n",
    "\n",
    "**Using Databricks Foundation Models (FREE) or OpenAI**\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83D\uDCCD Scenario\n",
    "\n",
    "You are working for an **auto insurance company** that processes thousands of claims submitted as free-form text. The business goal is to transform these unstructured claim descriptions into **consistent, machine-actionable decisions** while maintaining traceability and control over each step of the reasoning process.\n",
    "\n",
    "Instead of relying on a single monolithic prompt, you will design a **multi-stage generative AI workflow** composed of specialized, task-aligned components. Each stage is responsible for a clearly defined task and produces structured output that can be validated and consumed downstream.\n",
    "\n",
    "---\n",
    "\n",
    "#### The workflow is composed of the following logical stages:\n",
    "\n",
    "1. **Extraction Stage**\n",
    "   A structured prompt extracts key fields—such as claim type, incident description, and severity—from a raw claim record stored in a Databricks table.\n",
    "\n",
    "2. **Policy Validation Stage**\n",
    "   A validation step determines whether the associated policy is active and eligible for coverage based on structured inputs.\n",
    "\n",
    "3. **Assessment Stage**\n",
    "   An LLM-driven reasoning step evaluates the extracted claim data and policy status to determine whether the claim should be auto-approved or flagged for manual review.\n",
    "\n",
    "4. **Resolution Stage**\n",
    "   A final structured response consolidates the outputs of previous stages into a machine-readable decision record suitable for downstream systems.\n",
    "\n",
    "---\n",
    "\n",
    "This design mirrors **real-world enterprise pipelines** where prompt-task alignment, structured outputs, tool ordering, and modular composition are essential for reliability, auditability, and scalability.\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83C\uDFAF Objective\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- **Apply prompt-task alignment** to ensure each stage of a workflow performs the correct LLM task (extraction, classification, or transformation).\n",
    "\n",
    "- **Design structured prompts** that produce consistent, machine-readable outputs suitable for automated pipelines.\n",
    "\n",
    "- **Translate a business use case** into a multi-stage AI pipeline with clearly defined inputs and outputs.\n",
    "\n",
    "- **Define and order reasoning steps** to ensure downstream components receive the correct data at the correct time.\n",
    "\n",
    "- **Use LangChain abstractions** to compose prompts, models, and reasoning stages without relying on monolithic prompts.\n",
    "\n",
    "- **Execute the workflow in Databricks**, using PySpark for data preparation and OpenAI models for structured reasoning.\n",
    "\n",
    "- **Observe how modular design** improves interpretability, debuggability, and control in generative AI systems.\n",
    "\n",
    "You will simulate the complete workflow inside a Databricks notebook, focusing on **design correctness** rather than optimization, to reinforce the architectural principles introduced in Chapter 2.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bb4f620-d9f5-4eeb-bdaf-b3e68d6682ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDCCB Prerequisites\n",
    "\n",
    "Before running this lab, ensure you have:\n",
    "\n",
    "#### **1. Databricks Environment**\n",
    "- A Databricks Workspace (Community Edition or paid tier)\n",
    "- Access to Foundation Model Serving Endpoints (available in most Databricks workspaces)\n",
    "\n",
    "#### **2. Model Endpoint Configuration**\n",
    "\n",
    "This notebook uses **Databricks Foundation Models** which are FREE and don't require API keys.\n",
    "\n",
    "**To configure your model endpoint:**\n",
    "\n",
    "1. In your Databricks workspace, navigate to: **Serving** → **Serving Endpoints**\n",
    "2. Look for available Foundation Model endpoints, such as:\n",
    "   - `databricks-meta-llama-3-3-70b-instruct` (recommended)\n",
    "   - `databricks-meta-llama-3-1-70b-instruct`\n",
    "   - `databricks-dbrx-instruct`\n",
    "   - `databricks-mixtral-8x7b-instruct`\n",
    "\n",
    "3. **Copy the endpoint name** (just the name, NOT the full URL)\n",
    "\n",
    "**The notebook is pre-configured with:** `databricks-meta-llama-3-3-70b-instruct`\n",
    "\n",
    "- ✅ If this model is available in your workspace: No changes needed!\n",
    "- ⚙️ If you need a different model: Update the endpoint name in **Step 5** below\n",
    "\n",
    "**Important:** Use only the endpoint **name** in your code:\n",
    "```python\n",
    "# ✅ CORRECT\n",
    "endpoint=\"databricks-meta-llama-3-3-70b-instruct\"\n",
    "\n",
    "# ❌ WRONG - Don't use the full URL\n",
    "endpoint=\"https://adb-1234567890.15.azuredatabricks.net/...\"\n",
    "```\n",
    "\n",
    "Databricks automatically resolves the endpoint name to the correct URL when running in your workspace.\n",
    "\n",
    "#### **3. Authentication**\n",
    "\n",
    "When running in Databricks:\n",
    "- ✅ No API keys needed - Databricks uses your workspace session\n",
    "- ✅ No URLs needed - Just the endpoint name\n",
    "- ✅ Completely FREE - Foundation Models are included\n",
    "\n",
    "#### **4. Alternative Model Options (Optional)**\n",
    "\n",
    "If you prefer to use other models instead of Databricks Foundation Models:\n",
    "- **OpenAI**: Requires API key and billing setup\n",
    "- **Azure OpenAI**: Requires Azure subscription\n",
    "- **Local Ollama**: Requires local installation\n",
    "\n",
    "See the model configuration section in **Step 5** for details.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92e1386d-f249-4406-a9ba-29b5fcdd0db9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDD27 Step 1: Install Required Packages\n",
    "\n",
    "To work with LangChain agents in a modern, non-deprecated way, you need to install the latest versions of the required libraries.\n",
    "\n",
    "**What's being installed:**\n",
    "\n",
    "- `langchain-openai`: The modern package for OpenAI integration with LangChain (replaces deprecated `langchain.llms.OpenAI`)\n",
    "- `langchain`: Core LangChain framework for building agent workflows (v1.0+)\n",
    "- `langchain-community`: Community-contributed tools and integrations (includes Databricks models)\n",
    "- `langchain-core`: Core abstractions including prompts, chains, and runnables\n",
    "- `langgraph`: Modern agent framework (required for `create_agent`)\n",
    "- `openai`: Official OpenAI Python client\n",
    "\n",
    "This ensures you're using the **current, supported APIs** without any deprecated imports.\n",
    "\n",
    "> ⚠️ **Note**: After installation, you'll need to restart the Python kernel to ensure the new packages are loaded properly.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDCA1 **Model Options Available**\n",
    "\n",
    "After installing these packages, you can use:\n",
    "- ✅ **OpenAI models** (requires API key and billing)\n",
    "- ✅ **Databricks Foundation Models** (FREE for Databricks users)\n",
    "- ✅ **Azure OpenAI** (for enterprise users)\n",
    "- ✅ **Local models via Ollama** (completely free)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a678e7b4-263d-4155-9bad-41174494ec79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%pip install --upgrade langchain-openai langchain langchain-community langchain-core langgraph openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9657147f-c110-4103-bcdd-677a6224851f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDD04 Step 2: Restart the Python Kernel\n",
    "\n",
    "After installing or upgrading packages in Databricks, it's important to restart the Python runtime so your notebook picks up the new dependencies cleanly.\n",
    "\n",
    "This ensures that:\n",
    "- All newly installed packages are available in the Python environment\n",
    "- No conflicts exist between old and new package versions\n",
    "- Import statements will reference the correct module versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd71d44a-3d98-4d50-baeb-1783d2d547b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56737ce7-9d66-4720-9fe4-8a9a6ed6bec3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDD11 Step 3: API Key Setup (OPTIONAL - Skip if Using Databricks Models)\n",
    "\n",
    "> ⚡ **Quick Note**: If you're using **Databricks Foundation Models** (the default in this notebook), you can **SKIP this entire step**. No API key needed!\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83C\uDFAF When Do You Need This Step?\n",
    "\n",
    "**Skip this step if:**\n",
    "- ✅ You're using Databricks Foundation Models (default option)\n",
    "- ✅ You want a completely FREE experience\n",
    "\n",
    "**Complete this step only if:**\n",
    "- ❌ You want to use OpenAI models (requires billing)\n",
    "- ❌ You want to use Azure OpenAI\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDCCC How to Get Your OpenAI API Key (Optional)\n",
    "\n",
    "1. Go to [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)\n",
    "2. Log in or create an OpenAI account\n",
    "3. Click **\"Create new secret key\"**\n",
    "4. Copy the generated key (it starts with `sk-...`)\n",
    "5. Keep it safe — you won't see it again!\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD10 How to Set the Key in Databricks\n",
    "\n",
    "You have **two options** for setting your API key:\n",
    "\n",
    "---\n",
    "\n",
    "##### **Option 1: Quick Setup (Development/Learning)**\n",
    "\n",
    "Paste your key directly in the cell below using `os.environ`:\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"  # Replace with your actual key\n",
    "```\n",
    "\n",
    "> ⚠️ **Important**: This method is for development and learning purposes only. Never commit API keys to version control!\n",
    "\n",
    "---\n",
    "\n",
    "##### **Option 2: Secure Setup (Production/Best Practice)**\n",
    "\n",
    "Use **Databricks Secrets** to securely store your API key:\n",
    "\n",
    "**Step 1: Create a secret scope (one-time setup)**\n",
    "```bash\n",
    "# In Databricks CLI or notebook\n",
    "databricks secrets create-scope --scope my-secrets\n",
    "```\n",
    "\n",
    "**Step 2: Store your API key**\n",
    "```bash\n",
    "databricks secrets put --scope my-secrets --key openai-api-key\n",
    "# This will open an editor where you paste your key\n",
    "```\n",
    "\n",
    "**Step 3: Retrieve the key in your notebook**\n",
    "```python\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(scope=\"my-secrets\", key=\"openai-api-key\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD27 **Choose Your Method Below**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bcd4b25-8183-4fc9-a22a-36fef961c91e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ⚡ SKIP THIS CELL if you're using Databricks Foundation Models (the default)\n",
    "\n",
    "# OPTION 1: Direct setup (for learning/development with OpenAI)\n",
    "# Uncomment the line below and add your key if you want to use OpenAI:\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # ⚠️ Replace with your actual key\n",
    "\n",
    "# OPTION 2: Secure setup (for production with OpenAI)\n",
    "# Uncomment the line below:\n",
    "# os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(scope=\"my-secrets\", key=\"openai-api-key\")\n",
    "\n",
    "# Verify the key is set (optional)\n",
    "if os.environ.get(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"):\n",
    "    print(\"✅ OpenAI API key is set correctly\")\n",
    "else:\n",
    "    print(\"ℹ️  No OpenAI API key set - that's OK if you're using Databricks Foundation Models!\")\n",
    "    print(\"   (This is the default and recommended option for this lab)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60a4ef76-c872-4338-9fc3-7cac2b6f6021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDDC3️ Step 4: Load Sample Claims Data into a Spark Table\n",
    "\n",
    "This step creates a simulated insurance claims dataset using PySpark. This represents the **raw, unstructured data** that your multi-agent workflow will process.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDCCA Dataset Structure\n",
    "\n",
    "The dataset includes the following fields:\n",
    "\n",
    "- **`claim_id`**: Unique identifier for each claim (e.g., C101, C102)\n",
    "- **`claimant_name`**: Name of the person who filed the claim\n",
    "- **`damage_description`**: Free-form text describing the incident (unstructured input)\n",
    "- **`estimated_damage`**: Approximate repair cost in dollars\n",
    "- **`policy_id`**: Reference to the insurance policy number\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83C\uDFAF Why This Matters\n",
    "\n",
    "In real-world scenarios, claims arrive as unstructured text from various sources (emails, forms, mobile apps). Your AI pipeline must:\n",
    "\n",
    "1. **Extract** structured information from this raw text\n",
    "2. **Validate** that the policy is active\n",
    "3. **Assess** whether the claim meets auto-approval criteria\n",
    "4. **Resolve** the claim with a final decision\n",
    "\n",
    "Once loaded, the data is registered as a temporary SQL view called `claims`, which can be queried by your agents during the workflow.\n",
    "\n",
    "> \uD83E\uDDEA This simulates a production data lake or warehouse table that would feed into your AI pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9a0c6cc-74d6-4e45-809b-f829c9149818",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "# Note: In Databricks, the 'spark' session is pre-initialized and ready to use\n",
    "# No need to create a SparkSession manually\n",
    "\n",
    "# Define schema and sample data\n",
    "schema = StructType([\n",
    "    StructField(\"claim_id\", StringType(), True),\n",
    "    StructField(\"claimant_name\", StringType(), True),\n",
    "    StructField(\"damage_description\", StringType(), True),\n",
    "    StructField(\"estimated_damage\", DoubleType(), True),\n",
    "    StructField(\"policy_id\", StringType(), True)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (\"C101\", \"Alice Jones\", \"Rear-end collision, bumper damage\", 2200.0, \"P1001\"),\n",
    "    (\"C102\", \"David Kim\", \"Broken windshield and headlight\", 850.0, \"P1002\"),\n",
    "    (\"C103\", \"Maria Patel\", \"Side door dent and paint scratch\", 1200.0, \"P1003\")\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.createOrReplaceTempView(\"claims\")\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2185f7c2-cc2d-4020-9939-88ea14962f78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83E\uDDE0 Step 5: Initialize the LLM (Multiple Options)\n",
    "\n",
    "In this step, you'll initialize a **language model** using the modern, non-deprecated API. You have several options depending on your needs and budget.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD04 What Changed from Older Versions?\n",
    "\n",
    "**Old (Deprecated) Way:**\n",
    "```python\n",
    "from langchain.llms import OpenAI  # ❌ Deprecated\n",
    "llm = OpenAI(temperature=0)\n",
    "```\n",
    "\n",
    "**New (Current) Way:**\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI  # ✅ Modern\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83C\uDFAF Model Options\n",
    "\n",
    "Choose one of the following options based on your situation:\n",
    "\n",
    "---\n",
    "\n",
    "##### **Option 1: OpenAI (Recommended for Production)**\n",
    "\n",
    "**Requirements**:\n",
    "- Valid OpenAI API key\n",
    "- Active billing account with available credits\n",
    "\n",
    "**Pros**:\n",
    "- Best performance and reliability\n",
    "- Excellent function calling support\n",
    "- Industry standard\n",
    "\n",
    "**Cons**:\n",
    "- Requires paid account\n",
    "- Usage-based pricing\n",
    "\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##### **Option 2: Databricks Foundation Models (Free for Databricks Users)**\n",
    "\n",
    "**Requirements**:\n",
    "- Databricks workspace with Foundation Model APIs enabled\n",
    "\n",
    "**Pros**:\n",
    "- ✅ **FREE** for Databricks users\n",
    "- No external API key needed\n",
    "- Integrated with Databricks security\n",
    "\n",
    "**Cons**:\n",
    "- Only available in Databricks environment\n",
    "- May have different capabilities than OpenAI\n",
    "\n",
    "```python\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "llm = ChatDatabricks(\n",
    "    endpoint=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##### **Option 3: Azure OpenAI (Enterprise)**\n",
    "\n",
    "**Requirements**:\n",
    "- Azure subscription\n",
    "- Azure OpenAI resource deployed\n",
    "\n",
    "**Pros**:\n",
    "- Enterprise-grade security and compliance\n",
    "- Data residency control\n",
    "- SLA guarantees\n",
    "\n",
    "**Cons**:\n",
    "- Requires Azure setup\n",
    "- More complex configuration\n",
    "\n",
    "```python\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://your-resource.openai.azure.com/\",\n",
    "    api_key=\"your-azure-key\",\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    "    temperature=0\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##### **Option 4: Local Models with Ollama (Completely Free)**\n",
    "\n",
    "**Requirements**:\n",
    "- Ollama installed locally or on cluster\n",
    "- Sufficient compute resources\n",
    "\n",
    "**Pros**:\n",
    "- ✅ **100% FREE**\n",
    "- No API keys needed\n",
    "- Complete data privacy\n",
    "- No rate limits\n",
    "\n",
    "**Cons**:\n",
    "- Requires local setup\n",
    "- May have lower quality outputs\n",
    "- Slower inference\n",
    "\n",
    "```python\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3\",\n",
    "    temperature=0\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ⚙️ Configuration Parameters\n",
    "\n",
    "- **`model`**: Specifies which model to use\n",
    "- **`temperature=0`**: Makes outputs deterministic (same input = same output), which is critical for production pipelines\n",
    "\n",
    "> \uD83D\uDCA1 **Best Practice**: Always use `temperature=0` for business logic and decision-making tasks to ensure consistency and reliability.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDEA8 **Troubleshooting OpenAI Errors**\n",
    "\n",
    "If you see errors like:\n",
    "- **`AuthenticationError (401)`**: Your API key is invalid or not set correctly\n",
    "- **`RateLimitError (429)`**: You've exceeded your quota or don't have billing set up\n",
    "\n",
    "**Solutions**:\n",
    "1. Check your OpenAI billing at: https://platform.openai.com/account/billing\n",
    "2. Add credits to your account\n",
    "3. Or switch to **Option 2 (Databricks Foundation Models)** which is FREE\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD27 **Choose Your Model Below**\n",
    "\n",
    "> \uD83D\uDCCC **IMPORTANT**: If you're using Databricks Foundation Models (default), make sure the endpoint name below matches what's available in YOUR workspace. See the **\"Databricks Workspace Setup\"** section at the top of this notebook for instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c031a8a-f9eb-4dd6-b6cb-bf2661673f6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatDatabricks\n",
    "\n",
    "# OPTION 2: Databricks Foundation Models (FREE - RECOMMENDED) ⭐\n",
    "# This is the default option - no API keys or billing required!\n",
    "#\n",
    "# ⚠️ CONFIGURATION: Update the endpoint name if needed\n",
    "# - Go to your Databricks workspace: Serving → Serving Endpoints\n",
    "# - Find an available Foundation Model endpoint\n",
    "# - Replace the endpoint name below with YOUR endpoint name (just the name, NOT the full URL)\n",
    "#\n",
    "# ✅ CORRECT: endpoint=\"databricks-meta-llama-3-3-70b-instruct\"\n",
    "# ❌ WRONG:   endpoint=\"https://adb-123456.azuredatabricks.net/...\"\n",
    "#\n",
    "llm = ChatDatabricks(\n",
    "    endpoint=\"databricks-meta-llama-3-3-70b-instruct\",  # ← Change this if needed\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# OPTION 1: OpenAI (requires valid API key and billing)\n",
    "# Uncomment the lines below to use OpenAI instead:\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# OPTION 3: Azure OpenAI (for enterprise users)\n",
    "# Uncomment and configure the lines below:\n",
    "# from langchain_openai import AzureChatOpenAI\n",
    "# llm = AzureChatOpenAI(\n",
    "#     azure_endpoint=\"https://your-resource.openai.azure.com/\",\n",
    "#     api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "#     api_version=\"2024-02-15-preview\",\n",
    "#     deployment_name=\"gpt-35-turbo\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# OPTION 4: Local Ollama (completely free, requires Ollama installed)\n",
    "# Uncomment the lines below:\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# llm = ChatOllama(model=\"llama3\", temperature=0)\n",
    "\n",
    "print(f\"✅ LLM initialized: {llm.__class__.__name__}\")\n",
    "print(f\"✅ Using Databricks Foundation Model: databricks-meta-llama-3-3-70b-instruct\")\n",
    "print(f\"✅ Cost: FREE (included with Databricks)\")\n",
    "print(f\"✅ No API keys required!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43d6eaa6-5259-4182-9214-67159bf92db8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDCDD Step 6: Create Structured Prompts for Each Workflow Stage\n",
    "\n",
    "In this step, you'll define **prompt templates** for each of the four stages in your multi-agent workflow. Each prompt is designed to perform a specific task and produce structured, machine-readable output.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83C\uDFAF The Four Stages\n",
    "\n",
    "1. **Extraction Stage**: Extract structured fields from raw claim data\n",
    "2. **Policy Validation Stage**: Determine if a policy is active and eligible\n",
    "3. **Assessment Stage**: Decide if the claim should be auto-approved or manually reviewed\n",
    "4. **Resolution Stage**: Generate the final decision record\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD0D Why Structured Prompts Matter\n",
    "\n",
    "- **Consistency**: Each stage produces predictable output formats\n",
    "- **Modularity**: Stages can be tested, debugged, and improved independently\n",
    "- **Traceability**: You can audit each step of the decision-making process\n",
    "- **Downstream Integration**: Structured outputs can be consumed by databases, APIs, or other systems\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDCD0 Prompt Design Principles\n",
    "\n",
    "Each prompt follows these best practices:\n",
    "\n",
    "- **Clear task definition**: Tells the LLM exactly what to do\n",
    "- **Structured output format**: Specifies how the response should be formatted\n",
    "- **Minimal ambiguity**: Uses precise language to reduce variability\n",
    "- **Context-appropriate**: Tailored to the specific stage's responsibility\n",
    "\n",
    "> \uD83E\uDDE9 This is a core principle of **prompt-task alignment**: matching the right prompt structure to the right type of task.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDCE6 Modern Import Structure\n",
    "\n",
    "**Important**: We're using `langchain_core.prompts` instead of the older `langchain.prompts`:\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import PromptTemplate  # ✅ Modern\n",
    "```\n",
    "\n",
    "This is part of LangChain's modular architecture where core abstractions live in `langchain-core`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f04cbfca-17f6-496f-bf60-7612c8a0807f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Stage 1: Extraction Prompt\n",
    "extraction_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an insurance claim data extraction specialist.\n",
    "\n",
    "Extract the following structured information from this claim:\n",
    "\n",
    "Claim Data: {claim_data}\n",
    "\n",
    "Provide the output in this exact format:\n",
    "- Claim ID: [value]\n",
    "- Claimant Name: [value]\n",
    "- Incident Type: [classify as: collision, vandalism, weather, or other]\n",
    "- Damage Description: [value]\n",
    "- Estimated Cost: [value]\n",
    "- Policy ID: [value]\n",
    "- Severity: [classify as: low, medium, or high based on cost]\n",
    "\n",
    "Be precise and use only the information provided.\"\"\"\n",
    ")\n",
    "\n",
    "# Stage 2: Policy Validation Prompt\n",
    "validation_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are a policy validation specialist.\n",
    "\n",
    "Policy ID: {policy_id}\n",
    "Policy Status: {policy_status}\n",
    "\n",
    "Determine if this policy is eligible for claim processing.\n",
    "\n",
    "Provide the output in this exact format:\n",
    "- Policy ID: [value]\n",
    "- Status: [Active/Inactive]\n",
    "- Eligible for Coverage: [Yes/No]\n",
    "- Reason: [brief explanation]\"\"\"\n",
    ")\n",
    "\n",
    "# Stage 3: Assessment Prompt\n",
    "assessment_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are a claim assessment specialist.\n",
    "\n",
    "Claim Information:\n",
    "{claim_info}\n",
    "\n",
    "Policy Status:\n",
    "{policy_status}\n",
    "\n",
    "Based on the following rules:\n",
    "1. If estimated cost > $2000, flag for manual review\n",
    "2. If policy is not active, reject automatically\n",
    "3. If cost <= $2000 and policy is active, auto-approve\n",
    "\n",
    "Provide the output in this exact format:\n",
    "- Decision: [Auto-Approve/Manual Review/Reject]\n",
    "- Reason: [brief explanation]\n",
    "- Estimated Cost: [value]\n",
    "- Risk Level: [Low/Medium/High]\"\"\"\n",
    ")\n",
    "\n",
    "# Stage 4: Resolution Prompt\n",
    "resolution_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are a claim resolution specialist.\n",
    "\n",
    "Assessment Result:\n",
    "{assessment}\n",
    "\n",
    "Generate a final decision record in this exact format:\n",
    "- Final Decision: [Approved/Pending Review/Rejected]\n",
    "- Next Steps: [specific actions required]\n",
    "- Processing Status: [Complete/Requires Human Review]\n",
    "- Timestamp: [current stage]\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44db0eeb-69fa-4e87-93f4-de5a43a9640d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDEE0️ Step 7: Define Tool Functions for Multi-Agent Workflow\n",
    "\n",
    "This step defines four custom Python functions that act as **tools** for your LangChain agent. Each tool corresponds to one of the four workflow stages and encapsulates the business logic for that stage.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD27 Tool 1: Extract Claim Details (Extraction Stage)\n",
    "\n",
    "**Purpose**: Query the Spark table and retrieve raw claim data\n",
    "\n",
    "**Input**: `claim_id` (string)\n",
    "\n",
    "**Output**: Formatted string with claim details\n",
    "\n",
    "**Business Logic**:\n",
    "- Queries the `claims` table using Spark SQL\n",
    "- Returns structured claim information if found\n",
    "- Returns error message if claim ID doesn't exist\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD27 Tool 2: Validate Policy (Policy Validation Stage)\n",
    "\n",
    "**Purpose**: Check if a policy is active and eligible for coverage\n",
    "\n",
    "**Input**: `policy_id` (string)\n",
    "\n",
    "**Output**: Policy validation status\n",
    "\n",
    "**Business Logic**:\n",
    "- Simulates a policy database lookup\n",
    "- Checks against a list of valid policy IDs\n",
    "- Returns validation result with eligibility status\n",
    "\n",
    "> \uD83D\uDCDD **Note**: In production, this would query a real policy management system or database.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD27 Tool 3: Assess Damage with LLM (Assessment Stage)\n",
    "\n",
    "**Purpose**: Use the LLM to evaluate claim data and make an approval decision\n",
    "\n",
    "**Input**: Claim information text\n",
    "\n",
    "**Output**: Assessment decision (Auto-Approve/Manual Review/Reject)\n",
    "\n",
    "**Business Logic**:\n",
    "- Extracts the dollar amount from the claim text\n",
    "- Invokes the LLM with the assessment prompt\n",
    "- Returns structured decision based on business rules\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD27 Tool 4: Finalize Resolution (Resolution Stage)\n",
    "\n",
    "**Purpose**: Generate the final decision record\n",
    "\n",
    "**Input**: Assessment result\n",
    "\n",
    "**Output**: Final formatted decision message\n",
    "\n",
    "**Business Logic**:\n",
    "- Takes the assessment output\n",
    "- Formats it into a final resolution message\n",
    "- Prepares the output for downstream systems\n",
    "\n",
    "---\n",
    "\n",
    "> \uD83E\uDDE9 These functions will be wrapped as LangChain tools in the next step, allowing a reasoning agent to call them dynamically based on the task prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c40cb50c-289f-481f-b599-0ebf16857378",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Tool 1: Extract Claim Details from Spark Table\n",
    "def extract_claim_details(claim_id):\n",
    "    \"\"\"\n",
    "    Extraction Stage: Retrieve raw claim data from the Spark table.\n",
    "\n",
    "    Args:\n",
    "        claim_id: Unique identifier for the claim\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with claim details or error message\n",
    "    \"\"\"\n",
    "    # Use DataFrame API with column-based filtering (Databricks best practice)\n",
    "    # This avoids SQL injection and is more efficient\n",
    "    from pyspark.sql import functions as F\n",
    "\n",
    "    claim_df = spark.table(\"claims\").filter(F.col(\"claim_id\") == claim_id)\n",
    "    claim = claim_df.first()\n",
    "\n",
    "    if not claim:\n",
    "        return f\"No claim found for ID {claim_id}\"\n",
    "\n",
    "    # Return structured claim data\n",
    "    return f\"Claimant: {claim.claimant_name}, Damage: {claim.damage_description}, Estimate: ${claim.estimated_damage}, Policy#: {claim.policy_id}\"\n",
    "\n",
    "\n",
    "# Tool 2: Validate Policy Status\n",
    "def validate_policy(policy_id):\n",
    "    \"\"\"\n",
    "    Policy Validation Stage: Check if a policy is active and eligible.\n",
    "\n",
    "    Args:\n",
    "        policy_id: Policy identifier to validate\n",
    "\n",
    "    Returns:\n",
    "        Policy validation status message\n",
    "    \"\"\"\n",
    "    # Simulate valid policies (in production, this would query a policy database)\n",
    "    valid_policies = {\"P1001\", \"P1002\", \"P1003\"}\n",
    "\n",
    "    if policy_id in valid_policies:\n",
    "        return f\"Policy {policy_id} is valid and active.\"\n",
    "    else:\n",
    "        return f\"Policy {policy_id} is NOT valid or inactive.\"\n",
    "\n",
    "\n",
    "# Tool 3: Assess Damage Using LLM\n",
    "def assess_damage_llm(text):\n",
    "    \"\"\"\n",
    "    Assessment Stage: Use LLM to evaluate claim and determine approval decision.\n",
    "\n",
    "    Args:\n",
    "        text: Claim information text containing cost estimate\n",
    "\n",
    "    Returns:\n",
    "        LLM-generated assessment decision\n",
    "    \"\"\"\n",
    "    # Extract dollar amount from text\n",
    "    amount_match = re.search(r\"\\$?(\\d+[.,]?\\d*)\", text)\n",
    "    if not amount_match:\n",
    "        return \"Could not extract a valid dollar amount from the claim.\"\n",
    "\n",
    "    amount = amount_match.group(1)\n",
    "\n",
    "    # Invoke LLM with assessment prompt\n",
    "    assessment_result = llm.invoke(\n",
    "        assessment_prompt.format(\n",
    "            claim_info=text,\n",
    "            policy_status=\"Active\"  # This would come from validate_policy in real workflow\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return assessment_result.content\n",
    "\n",
    "\n",
    "# Tool 4: Finalize Resolution\n",
    "def finalize_resolution(assessment):\n",
    "    \"\"\"\n",
    "    Resolution Stage: Generate final decision record.\n",
    "\n",
    "    Args:\n",
    "        assessment: Assessment result from previous stage\n",
    "\n",
    "    Returns:\n",
    "        Final formatted decision message\n",
    "    \"\"\"\n",
    "    return f\"Final decision: {assessment}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5aa2ad8-867d-420f-9142-7b521e0873c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83E\uDD16 Step 8: Register Tools and Initialize a Reasoning Agent\n",
    "\n",
    "Now that your helper functions are ready, you'll convert them into **LangChain-compatible tools** and initialize a **reasoning agent** using the modern OpenAI API.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD27 What Are LangChain Tools?\n",
    "\n",
    "Tools are functions that an agent can call to perform specific tasks. Each tool has:\n",
    "\n",
    "- **Name**: A unique identifier the agent uses to reference the tool\n",
    "- **Function**: The Python function to execute\n",
    "- **Description**: Instructions that tell the agent when and how to use the tool\n",
    "\n",
    "The agent reads these descriptions and decides which tools to call based on the user's request.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83E\uDDE0 Agent Type: `create_agent`\n",
    "\n",
    "We're using the **modern `create_agent` API** from LangChain v1, which is the current recommended way to build agents.\n",
    "\n",
    "**How the Agent Works:**\n",
    "\n",
    "1. **Reason**: The agent analyzes the task and decides what to do\n",
    "2. **Act**: The agent calls a tool to perform an action\n",
    "3. **Observe**: The agent examines the tool's output\n",
    "4. **Repeat**: The agent continues reasoning and acting until the task is complete\n",
    "\n",
    "This uses the ReAct (Reasoning + Acting) pattern under the hood.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD04 Modern vs. Deprecated Approach\n",
    "\n",
    "**Old (Deprecated) Way:**\n",
    "```python\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "```\n",
    "\n",
    "**New (Current) Way:**\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful insurance claim processing assistant.\"\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83C\uDFAF Why This Matters\n",
    "\n",
    "- **Non-deprecated**: Uses the current LangChain API\n",
    "- **More flexible**: Allows custom prompts and better control\n",
    "- **Production-ready**: Follows modern best practices\n",
    "\n",
    "> \uD83D\uDCA1 The agent will automatically orchestrate the four-stage workflow by calling the tools in the correct order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59ee350e-f63b-4bfc-bd68-faaf22f55725",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Define tools using the @tool decorator (modern approach)\n",
    "@tool\n",
    "def extract_claim(claim_id: str) -> str:\n",
    "    \"\"\"Look up claim details from the Spark database. Input should be a claim ID like 'C101'.\"\"\"\n",
    "    return extract_claim_details(claim_id)\n",
    "\n",
    "@tool\n",
    "def validate_policy_tool(policy_id: str) -> str:\n",
    "    \"\"\"Check if a policy is valid and active. Input should be a policy ID like 'P1001'.\"\"\"\n",
    "    return validate_policy(policy_id)\n",
    "\n",
    "@tool\n",
    "def assess_damage(claim_info: str) -> str:\n",
    "    \"\"\"Assess claim damage and determine approval decision. Input should be claim information text with cost estimate.\"\"\"\n",
    "    return assess_damage_llm(claim_info)\n",
    "\n",
    "@tool\n",
    "def finalize_resolution_tool(assessment: str) -> str:\n",
    "    \"\"\"Generate the final claim decision. Input should be the assessment result.\"\"\"\n",
    "    return finalize_resolution(assessment)\n",
    "\n",
    "# Create list of tools\n",
    "tools = [extract_claim, validate_policy_tool, assess_damage, finalize_resolution_tool]\n",
    "\n",
    "# Create the agent using the modern create_agent API\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"\"\"You are a helpful insurance claim processing assistant.\n",
    "\n",
    "Your job is to process insurance claims through a multi-stage workflow:\n",
    "1. Extract claim details using the claim ID\n",
    "2. Validate the policy is active\n",
    "3. Assess the damage and determine if it should be auto-approved or manually reviewed\n",
    "4. Finalize the resolution with a decision\n",
    "\n",
    "Always follow these steps in order and provide clear reasoning for your decisions.\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "969c6a77-3019-495a-a890-d9de7ae5b19c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDE80 Step 9: Execute the Multi-Agent Workflow\n",
    "\n",
    "Now it's time to run the complete workflow! The agent will process a claim by automatically orchestrating all four stages.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDD04 What Happens When You Run This?\n",
    "\n",
    "When you execute `agent.invoke()`, the agent will:\n",
    "\n",
    "1. **Read your prompt**: \"Process claim C101\"\n",
    "2. **Plan the workflow**: Determine which tools to call and in what order\n",
    "3. **Execute Stage 1 (Extraction)**: Call `extract_claim` to retrieve claim data\n",
    "4. **Execute Stage 2 (Validation)**: Call `validate_policy_tool` to check policy status\n",
    "5. **Execute Stage 3 (Assessment)**: Call `assess_damage` to evaluate the claim\n",
    "6. **Execute Stage 4 (Resolution)**: Call `finalize_resolution_tool` to generate the final decision\n",
    "7. **Return the result**: Provide a complete, structured response\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83E\uDDE0 Observing the Reasoning Process\n",
    "\n",
    "The agent will show you its internal reasoning process in the output:\n",
    "\n",
    "- **Tool Calls**: Which tools the agent decides to use\n",
    "- **Tool Inputs**: What data it passes to each tool\n",
    "- **Tool Outputs**: What each tool returns\n",
    "- **Final Answer**: The complete result\n",
    "\n",
    "This transparency is crucial for:\n",
    "- **Debugging**: Understanding why the agent made certain decisions\n",
    "- **Auditing**: Tracking the decision-making process for compliance\n",
    "- **Optimization**: Identifying bottlenecks or inefficiencies\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDCCA Expected Output\n",
    "\n",
    "For claim C101 (Alice Jones, $2200 damage):\n",
    "\n",
    "- **Extraction**: Successfully retrieves claim details\n",
    "- **Validation**: Confirms policy P1001 is active\n",
    "- **Assessment**: Flags for manual review (cost > $2000)\n",
    "- **Resolution**: Generates final decision record\n",
    "\n",
    "> \uD83D\uDCA1 Try running this with different claim IDs (C102, C103) to see how the workflow adapts to different scenarios!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9480669a-4fca-4fd5-9ae0-f07b4ed1b794",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run the multi-agent workflow on claim C101\n",
    "try:\n",
    "    result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Process claim C101\"}]})\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL RESULT:\")\n",
    "    print(\"=\"*60)\n",
    "    # Extract the final message from the agent\n",
    "    final_message = result[\"messages\"][-1]\n",
    "    print(final_message.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nTrying alternative invocation method...\")\n",
    "    # Alternative method for some model providers\n",
    "    result = agent.invoke({\"messages\": [(\"user\", \"Process claim C101\")]})\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL RESULT:\")\n",
    "    print(\"=\"*60)\n",
    "    final_message = result[\"messages\"][-1]\n",
    "    print(final_message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b8cec79-47c2-4ecf-9e4b-3d696312af63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDD0D Step 10: Test with Additional Claims\n",
    "\n",
    "Let's test the workflow with the other claims to see how it handles different scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDCCB Test Scenarios\n",
    "\n",
    "**Claim C102** (David Kim):\n",
    "- Estimated damage: $850\n",
    "- Expected outcome: Auto-approve (cost < $2000)\n",
    "\n",
    "**Claim C103** (Maria Patel):\n",
    "- Estimated damage: $1200\n",
    "- Expected outcome: Auto-approve (cost < $2000)\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83C\uDFAF What to Observe\n",
    "\n",
    "Pay attention to how the agent:\n",
    "\n",
    "1. **Adapts its reasoning** based on different cost amounts\n",
    "2. **Maintains consistency** in the workflow structure\n",
    "3. **Produces structured outputs** at each stage\n",
    "4. **Makes different decisions** based on business rules\n",
    "\n",
    "This demonstrates the power of **modular, multi-stage workflows** where each component has a clear responsibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bf4182d-b3e0-429a-b499-923ff7d40655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test with claim C102 (lower cost - should auto-approve)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING CLAIM C102\")\n",
    "print(\"=\"*60)\n",
    "try:\n",
    "    result_c102 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Process claim C102\"}]})\n",
    "except:\n",
    "    result_c102 = agent.invoke({\"messages\": [(\"user\", \"Process claim C102\")]})\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULT FOR C102:\")\n",
    "print(\"=\"*60)\n",
    "print(result_c102[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f282ef1-8cba-43e4-80c7-45ea074faf1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test with claim C103 (medium cost - should auto-approve)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING CLAIM C103\")\n",
    "print(\"=\"*60)\n",
    "try:\n",
    "    result_c103 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Process claim C103\"}]})\n",
    "except:\n",
    "    result_c103 = agent.invoke({\"messages\": [(\"user\", \"Process claim C103\")]})\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULT FOR C103:\")\n",
    "print(\"=\"*60)\n",
    "print(result_c103[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdeb995c-1f15-42f5-9af7-a336fc291dff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ✅ Understanding the Multi-Agent Workflow Output\n",
    "\n",
    "Congratulations! You've successfully built and executed a **multi-stage generative AI workflow** for insurance claim processing.\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83C\uDFAF Key Takeaways\n",
    "\n",
    "**1. Prompt-Task Alignment**\n",
    "- Each stage had a specific prompt designed for its task (extraction, validation, assessment, resolution)\n",
    "- This ensures the LLM performs the correct type of reasoning at each step\n",
    "\n",
    "**2. Structured Outputs**\n",
    "- Every stage produced machine-readable, consistent outputs\n",
    "- These outputs can be validated, logged, and consumed by downstream systems\n",
    "\n",
    "**3. Modular Design**\n",
    "- Each tool is independent and can be tested separately\n",
    "- Changes to one stage don't break the entire workflow\n",
    "- Easy to add new stages or modify existing ones\n",
    "\n",
    "**4. Tool Ordering**\n",
    "- The agent automatically determined the correct sequence of operations\n",
    "- Data flows logically from extraction → validation → assessment → resolution\n",
    "\n",
    "**5. Observability**\n",
    "- The verbose output shows every step of the reasoning process\n",
    "- This is essential for debugging, auditing, and compliance\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83C\uDFE2 Real-World Applications\n",
    "\n",
    "This pattern applies to many enterprise scenarios:\n",
    "\n",
    "- **Financial Services**: Loan application processing, fraud detection\n",
    "- **Healthcare**: Medical claim adjudication, patient triage\n",
    "- **Customer Service**: Ticket routing, automated responses\n",
    "- **Legal**: Contract analysis, compliance checking\n",
    "- **HR**: Resume screening, candidate evaluation\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDE80 Next Steps\n",
    "\n",
    "To extend this lab, you could:\n",
    "\n",
    "1. **Add more validation rules** (e.g., check claim history, verify claimant identity)\n",
    "2. **Implement structured output parsing** using Pydantic models\n",
    "3. **Add error handling** for edge cases and invalid inputs\n",
    "4. **Integrate with real databases** instead of simulated data\n",
    "5. **Add logging and monitoring** for production deployment\n",
    "6. **Implement human-in-the-loop** for manual review cases\n",
    "7. **Create unit tests** for each tool function\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDCDA What You've Learned\n",
    "\n",
    "By completing this lab, you've demonstrated:\n",
    "\n",
    "✅ How to design multi-stage AI workflows with clear task boundaries\n",
    "✅ How to use modern LangChain APIs without deprecated code\n",
    "✅ How to create structured prompts for consistent outputs\n",
    "✅ How to orchestrate multiple tools using a reasoning agent\n",
    "✅ How to execute AI workflows in Databricks with PySpark integration\n",
    "✅ How modular design improves reliability and maintainability\n",
    "\n",
    "---\n",
    "\n",
    "> \uD83C\uDF93 **Certification Tip**: The concepts in this lab—prompt-task alignment, structured outputs, tool composition, and modular workflows—are core topics in the Databricks Generative AI Engineer Associate certification exam.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f15b03b-de24-49a6-b9e8-e21dcbfc0793",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83C\uDF93 Summary: Architecture Principles Demonstrated\n",
    "\n",
    "This lab reinforced the following architectural principles from Chapter 2:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1️⃣ **Separation of Concerns**\n",
    "Each stage has a single, well-defined responsibility:\n",
    "- Extraction: Parse raw data\n",
    "- Validation: Check eligibility\n",
    "- Assessment: Make decisions\n",
    "- Resolution: Format outputs\n",
    "\n",
    "---\n",
    "\n",
    "#### 2️⃣ **Composability**\n",
    "Tools can be combined in different ways:\n",
    "- Add new tools without changing existing ones\n",
    "- Reorder stages for different workflows\n",
    "- Reuse tools across multiple agents\n",
    "\n",
    "---\n",
    "\n",
    "#### 3️⃣ **Testability**\n",
    "Each component can be tested independently:\n",
    "- Unit test individual tool functions\n",
    "- Integration test the full workflow\n",
    "- Mock external dependencies (databases, APIs)\n",
    "\n",
    "---\n",
    "\n",
    "#### 4️⃣ **Observability**\n",
    "The workflow provides full visibility:\n",
    "- Verbose logging shows reasoning steps\n",
    "- Structured outputs enable monitoring\n",
    "- Clear error messages aid debugging\n",
    "\n",
    "---\n",
    "\n",
    "#### 5️⃣ **Scalability**\n",
    "The design supports production deployment:\n",
    "- Stateless tools can run in parallel\n",
    "- Modular architecture enables horizontal scaling\n",
    "- Clear interfaces support microservices architecture\n",
    "\n",
    "---\n",
    "\n",
    "> \uD83C\uDFC6 **Well done!** You've completed the hands-on lab for Chapter 2: Multi-Agent Workflow with LangChain + OpenAI in Databricks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d5b34fe-bf1c-4fe5-aa47-37e13ee97d07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDD27 Troubleshooting Common Issues\n",
    "\n",
    "If you encounter errors while running this notebook, here are solutions to common problems:\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ **Error: `Endpoint not found` or `Model endpoint does not exist`**\n",
    "\n",
    "**Problem**: The Databricks model endpoint name doesn't match what's available in your workspace\n",
    "\n",
    "**Solutions**:\n",
    "1. **Check available endpoints in your workspace**:\n",
    "   - Navigate to: **Serving** → **Serving Endpoints** in Databricks\n",
    "   - Look for Foundation Model endpoints (e.g., `databricks-meta-llama-3-3-70b-instruct`)\n",
    "   - Copy the exact endpoint name\n",
    "\n",
    "2. **Update the endpoint in Step 5**:\n",
    "   ```python\n",
    "   llm = ChatDatabricks(\n",
    "       endpoint=\"YOUR-ENDPOINT-NAME-HERE\",  # ← Paste your endpoint name\n",
    "       temperature=0\n",
    "   )\n",
    "   ```\n",
    "\n",
    "3. **Common endpoint names to try**:\n",
    "   - `databricks-meta-llama-3-3-70b-instruct` (recommended)\n",
    "   - `databricks-meta-llama-3-1-70b-instruct`\n",
    "   - `databricks-dbrx-instruct`\n",
    "   - `databricks-mixtral-8x7b-instruct`\n",
    "\n",
    "4. **Make sure you're using the endpoint NAME, not the URL**:\n",
    "   - ✅ CORRECT: `endpoint=\"databricks-meta-llama-3-3-70b-instruct\"`\n",
    "   - ❌ WRONG: `endpoint=\"https://adb-123456.azuredatabricks.net/...\"`\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ **Error: `AuthenticationError: Error code: 401`**\n",
    "\n",
    "**Problem**: Invalid or missing OpenAI API key\n",
    "\n",
    "**Solutions**:\n",
    "1. **Check your API key is set correctly**:\n",
    "   ```python\n",
    "   import os\n",
    "   print(os.environ.get(\"OPENAI_API_KEY\", \"NOT SET\")[:10] + \"...\")\n",
    "   ```\n",
    "   Should show: `sk-proj-...` or `sk-...`\n",
    "\n",
    "2. **Verify your key is valid** at: https://platform.openai.com/account/api-keys\n",
    "\n",
    "3. **Switch to Databricks Foundation Models (FREE)**:\n",
    "   ```python\n",
    "   from langchain_community.chat_models import ChatDatabricks\n",
    "   llm = ChatDatabricks(\n",
    "       endpoint=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "       temperature=0\n",
    "   )\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ **Error: `RateLimitError: Error code: 429`**\n",
    "\n",
    "**Problem**: OpenAI quota exceeded or no billing set up\n",
    "\n",
    "**Solutions**:\n",
    "1. **Check your OpenAI billing**: https://platform.openai.com/account/billing\n",
    "   - Add credits to your account\n",
    "   - Verify you have an active payment method\n",
    "\n",
    "2. **Use Databricks Foundation Models instead (FREE)**:\n",
    "   ```python\n",
    "   from langchain_community.chat_models import ChatDatabricks\n",
    "   llm = ChatDatabricks(\n",
    "       endpoint=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "       temperature=0\n",
    "   )\n",
    "   ```\n",
    "   Then re-run the agent creation cell and execution cells.\n",
    "\n",
    "3. **Use a local model with Ollama (FREE)**:\n",
    "   ```bash\n",
    "   # Install Ollama first: https://ollama.ai\n",
    "   ollama pull llama3\n",
    "   ```\n",
    "   ```python\n",
    "   from langchain_community.chat_models import ChatOllama\n",
    "   llm = ChatOllama(model=\"llama3\", temperature=0)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ **Error: `ModuleNotFoundError: No module named 'langchain_openai'`**\n",
    "\n",
    "**Problem**: Packages not installed or kernel not restarted\n",
    "\n",
    "**Solutions**:\n",
    "1. **Re-run the installation cell**:\n",
    "   ```python\n",
    "   %pip install --upgrade langchain-openai langchain langchain-community langchain-core langgraph openai\n",
    "   ```\n",
    "\n",
    "2. **Restart the Python kernel**:\n",
    "   ```python\n",
    "   %restart_python\n",
    "   ```\n",
    "\n",
    "3. **Verify installation**:\n",
    "   ```python\n",
    "   import langchain\n",
    "   import langchain_openai\n",
    "   print(f\"LangChain version: {langchain.__version__}\")\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ **Error: `ImportError: cannot import name 'create_agent'`**\n",
    "\n",
    "**Problem**: Old version of LangChain installed\n",
    "\n",
    "**Solutions**:\n",
    "1. **Upgrade to LangChain 1.0+**:\n",
    "   ```python\n",
    "   %pip install --upgrade langchain>=1.0.0\n",
    "   %restart_python\n",
    "   ```\n",
    "\n",
    "2. **Verify version**:\n",
    "   ```python\n",
    "   import langchain\n",
    "   print(langchain.__version__)  # Should be 1.0.0 or higher\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ **Error: `AnalysisException: Table or view not found: claims`**\n",
    "\n",
    "**Problem**: The claims table wasn't created\n",
    "\n",
    "**Solutions**:\n",
    "1. **Re-run the data loading cell** (Step 4):\n",
    "   ```python\n",
    "   df = spark.createDataFrame(data, schema)\n",
    "   df.createOrReplaceTempView(\"claims\")\n",
    "   ```\n",
    "\n",
    "2. **Verify the table exists**:\n",
    "   ```python\n",
    "   spark.sql(\"SELECT * FROM claims\").show()\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ **Error: Agent produces incorrect or incomplete results**\n",
    "\n",
    "**Problem**: Model quality or prompt issues\n",
    "\n",
    "**Solutions**:\n",
    "1. **Try a more capable model**:\n",
    "   ```python\n",
    "   llm = ChatOpenAI(model=\"gpt-4\", temperature=0)  # More expensive but better\n",
    "   ```\n",
    "\n",
    "2. **Check tool descriptions are clear**:\n",
    "   - Each `@tool` function should have a clear docstring\n",
    "   - The system prompt should be specific\n",
    "\n",
    "3. **Add more examples to prompts**:\n",
    "   - Include few-shot examples in your prompt templates\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ **Error: `dbutils is not defined` or Running Outside Databricks**\n",
    "\n",
    "**Problem**: You're trying to run this notebook outside of a Databricks environment\n",
    "\n",
    "**Solutions**:\n",
    "\n",
    "**Option 1: Use OpenAI instead (requires API key)**\n",
    "```python\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # Your OpenAI API key\n",
    "\n",
    "# Use OpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "```\n",
    "\n",
    "**Option 2: Use local Ollama (completely free)**\n",
    "```bash\n",
    "# Install Ollama first: https://ollama.ai\n",
    "ollama pull llama3\n",
    "```\n",
    "```python\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3\", temperature=0)\n",
    "```\n",
    "\n",
    "**Option 3: Run in Databricks (recommended for this lab)**\n",
    "- Upload this notebook to your Databricks workspace\n",
    "- Databricks Community Edition is FREE: https://databricks.com/try-databricks\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83D\uDCA1 **Best Practices for Success**\n",
    "\n",
    "1. ✅ **Always restart the kernel** after installing packages\n",
    "2. ✅ **Run cells in order** from top to bottom\n",
    "3. ✅ **Verify your model endpoint** matches what's available in your workspace\n",
    "4. ✅ **Use endpoint NAMES, not URLs** in your code\n",
    "5. ✅ **Use Databricks Foundation Models** if you don't have OpenAI credits\n",
    "6. ✅ **Read error messages carefully** - they usually tell you exactly what's wrong\n",
    "\n",
    "---\n",
    "\n",
    "#### \uD83C\uDD98 **Still Having Issues?**\n",
    "\n",
    "If you're still stuck:\n",
    "1. Check the [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)\n",
    "2. Review the [Databricks Documentation](https://docs.databricks.com/)\n",
    "3. Search for your error message on [Stack Overflow](https://stackoverflow.com/questions/tagged/langchain)\n",
    "4. Ask in the [LangChain Discord](https://discord.gg/langchain)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Orielly -Chapter 2-Multi-Agent Workflow with LangChain & OpenAI",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}